{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import log_hyperu as hyperu\n",
    "import tgr as tgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4798,  0.4873, -3.0128,  ...,  1.9991,  0.7848, -1.0195],\n",
      "        [-0.2106,  0.6268,  0.9318,  ..., -0.5429,  0.4307, -1.9257],\n",
      "        [ 1.2756, -1.1316,  0.8680,  ..., -0.8407, -0.3963, -0.2591],\n",
      "        ...,\n",
      "        [-1.3737,  0.0184,  1.1507,  ..., -0.8902,  0.5128, -0.5483],\n",
      "        [-0.4525,  1.2544,  1.0292,  ...,  0.3971, -0.7133, -0.6877],\n",
      "        [-0.3455, -0.0047, -0.2237,  ...,  0.0928,  0.3904,  1.0149]])\n"
     ]
    }
   ],
   "source": [
    "# Generating the data sets\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "# Structure of the data sets\n",
    "## Set X_A: Sparse Coefficients with many data points\n",
    "## Set X_B: Dense Coefficients with many data points\n",
    "## Set X_C: Sparse Coefficients with few data points\n",
    "## Set X_D: Dense Coefficients with few data points\n",
    "\n",
    "\n",
    "### Set X_A\n",
    "variables = 12\n",
    "sample = 100\n",
    "true_coefs = torch.tensor([[0],[0],[5.3],[4.2],[0],[0],[6.9],[0],[0],[0],[0],[0]])\n",
    "X = torch.randn(sample, variables)\n",
    "Y = X @ true_coefs + torch.randn(sample, 1) * 0.1\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 62.205291748046875\n",
      "Epoch [200/10000], Loss: 51.562259674072266\n",
      "Epoch [300/10000], Loss: 42.952903747558594\n",
      "Epoch [400/10000], Loss: 36.25038146972656\n",
      "Epoch [500/10000], Loss: 30.829273223876953\n",
      "Epoch [600/10000], Loss: 26.82758331298828\n",
      "Epoch [700/10000], Loss: 23.901168823242188\n",
      "Epoch [800/10000], Loss: 21.35123634338379\n",
      "Epoch [900/10000], Loss: 19.144800186157227\n",
      "Epoch [1000/10000], Loss: 17.229612350463867\n",
      "Epoch [1100/10000], Loss: 15.521501541137695\n",
      "Epoch [1200/10000], Loss: 14.230768203735352\n",
      "Epoch [1300/10000], Loss: 13.2305269241333\n",
      "Epoch [1400/10000], Loss: 12.223761558532715\n",
      "Epoch [1500/10000], Loss: 11.358625411987305\n",
      "Epoch [1600/10000], Loss: 10.62844467163086\n",
      "Epoch [1700/10000], Loss: 9.936694145202637\n",
      "Epoch [1800/10000], Loss: 9.407554626464844\n",
      "Epoch [1900/10000], Loss: 8.837451934814453\n",
      "Epoch [2000/10000], Loss: 8.326786041259766\n",
      "Epoch [2100/10000], Loss: 8.018985748291016\n",
      "Epoch [2200/10000], Loss: 7.5681681632995605\n",
      "Epoch [2300/10000], Loss: 7.228692531585693\n",
      "Epoch [2400/10000], Loss: 7.05301570892334\n",
      "Epoch [2500/10000], Loss: 6.75288724899292\n",
      "Epoch [2600/10000], Loss: 6.4145026206970215\n",
      "Epoch [2700/10000], Loss: 6.2606611251831055\n",
      "Epoch [2800/10000], Loss: 5.96408748626709\n",
      "Epoch [2900/10000], Loss: 5.893658638000488\n",
      "Epoch [3000/10000], Loss: 5.687401294708252\n",
      "Epoch [3100/10000], Loss: 5.59456205368042\n",
      "Epoch [3200/10000], Loss: 5.488216400146484\n",
      "Epoch [3300/10000], Loss: 5.363870620727539\n",
      "Epoch [3400/10000], Loss: 5.316135883331299\n",
      "Epoch [3500/10000], Loss: 5.168310165405273\n",
      "Epoch [3600/10000], Loss: 4.978005409240723\n",
      "Epoch [3700/10000], Loss: 5.016024112701416\n",
      "Epoch [3800/10000], Loss: 4.895753860473633\n",
      "Epoch [3900/10000], Loss: 4.906552314758301\n",
      "Epoch [4000/10000], Loss: 4.822268009185791\n",
      "Epoch [4100/10000], Loss: 4.748330593109131\n",
      "Epoch [4200/10000], Loss: 4.718062877655029\n",
      "Epoch [4300/10000], Loss: 4.68137264251709\n",
      "Epoch [4400/10000], Loss: 4.56518030166626\n",
      "Epoch [4500/10000], Loss: 4.546219825744629\n",
      "Epoch [4600/10000], Loss: 4.491897106170654\n",
      "Epoch [4700/10000], Loss: 4.522674083709717\n",
      "Epoch [4800/10000], Loss: 4.525602340698242\n",
      "Epoch [4900/10000], Loss: 4.475801944732666\n",
      "Epoch [5000/10000], Loss: 4.395211219787598\n",
      "Epoch [5100/10000], Loss: 4.360510349273682\n",
      "Epoch [5200/10000], Loss: 4.497951507568359\n",
      "Epoch [5300/10000], Loss: 4.372135639190674\n",
      "Epoch [5400/10000], Loss: 4.410710334777832\n",
      "Epoch [5500/10000], Loss: 4.3621110916137695\n",
      "Epoch [5600/10000], Loss: 4.272212982177734\n",
      "Epoch [5700/10000], Loss: 4.331776142120361\n",
      "Epoch [5800/10000], Loss: 4.357080936431885\n",
      "Epoch [5900/10000], Loss: 4.313193321228027\n",
      "Epoch [6000/10000], Loss: 4.294944763183594\n",
      "Epoch [6100/10000], Loss: 4.299490451812744\n",
      "Epoch [6200/10000], Loss: 4.312392711639404\n",
      "Epoch [6300/10000], Loss: 4.191317081451416\n",
      "Epoch [6400/10000], Loss: 4.250889778137207\n",
      "Epoch [6500/10000], Loss: 4.373144149780273\n",
      "Epoch [6600/10000], Loss: 4.014298915863037\n",
      "Epoch [6700/10000], Loss: 4.3041229248046875\n",
      "Epoch [6800/10000], Loss: 4.330819129943848\n",
      "Epoch [6900/10000], Loss: 4.2609992027282715\n",
      "Epoch [7000/10000], Loss: 4.290035247802734\n",
      "Epoch [7100/10000], Loss: 4.274087429046631\n",
      "Epoch [7200/10000], Loss: 4.266469955444336\n",
      "Epoch [7300/10000], Loss: 4.235105514526367\n",
      "Epoch [7400/10000], Loss: 4.203987121582031\n",
      "Epoch [7500/10000], Loss: 4.256718635559082\n",
      "Epoch [7600/10000], Loss: 4.300873279571533\n",
      "Epoch [7700/10000], Loss: 4.283336639404297\n",
      "Epoch [7800/10000], Loss: 4.353640079498291\n",
      "Epoch [7900/10000], Loss: 4.318350315093994\n",
      "Epoch [8000/10000], Loss: 4.298537254333496\n",
      "Epoch [8100/10000], Loss: 4.197147369384766\n",
      "Epoch [8200/10000], Loss: 4.262784957885742\n",
      "Epoch [8300/10000], Loss: 4.245819091796875\n",
      "Epoch [8400/10000], Loss: 4.241990566253662\n",
      "Epoch [8500/10000], Loss: 4.07599401473999\n",
      "Epoch [8600/10000], Loss: 4.319874286651611\n",
      "Epoch [8700/10000], Loss: 4.2349700927734375\n",
      "Epoch [8800/10000], Loss: 4.286506652832031\n",
      "Epoch [8900/10000], Loss: 4.299149036407471\n",
      "Epoch [9000/10000], Loss: 4.287696838378906\n",
      "Epoch [9100/10000], Loss: 4.2213335037231445\n",
      "Epoch [9200/10000], Loss: 4.20702600479126\n",
      "Epoch [9300/10000], Loss: 4.299666881561279\n",
      "Epoch [9400/10000], Loss: 4.284249305725098\n",
      "Epoch [9500/10000], Loss: 4.276865482330322\n",
      "Epoch [9600/10000], Loss: 4.278895378112793\n",
      "Epoch [9700/10000], Loss: 4.195788383483887\n",
      "Epoch [9800/10000], Loss: 4.275808334350586\n",
      "Epoch [9900/10000], Loss: 4.3088908195495605\n",
      "Epoch [10000/10000], Loss: 4.281039714813232\n",
      "[0.008788226172327995, -0.0036897389218211174, 5.2652716636657715, 4.164586544036865, 0.002791693899780512, 0.005356128327548504, 6.8540472984313965, 0.0024127820506691933, 0.004340313374996185, 0.0008273222483694553, 0.008651829324662685, 0.006634719204157591]\n"
     ]
    }
   ],
   "source": [
    "trained_model2, coefs, loss_of_optimization = tgr.TripleGammaModel(X, Y, 0.1, 0.51, 0.1, 2, True, num_epochs=10000) # Covariates, Targets, Penalty, a, c, kappa, normalization=True\n",
    "coefficients = trained_model2.linear.weight.detach().numpy()\n",
    "#intercept = trained_model2.linear.bias.item()\n",
    "\n",
    "#print(\"Coefficients General Function:\", coefficients)\n",
    "#print(\"Intercept General Function:\", intercept)\n",
    "print(coefficients[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 19.0645\n",
      "Epoch [200/1000], Loss: 15.7905\n",
      "Epoch [300/1000], Loss: 15.5970\n",
      "Epoch [400/1000], Loss: 15.5760\n",
      "Epoch [500/1000], Loss: 15.6062\n",
      "Epoch [600/1000], Loss: 15.5800\n",
      "Epoch [700/1000], Loss: 15.5879\n",
      "Epoch [800/1000], Loss: 15.5872\n",
      "Epoch [900/1000], Loss: 15.5942\n",
      "Epoch [1000/1000], Loss: 15.5884\n",
      "linear.weight: tensor([[-6.9520e-03, -7.7376e-03,  4.6682e+00,  3.6015e+00,  7.5944e-03,\n",
      "         -3.3017e-03,  6.1469e+00, -7.0554e-03,  3.5510e-03, -3.7710e-03,\n",
      "          1.5011e-03,  2.4193e-03]])\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "# Define your model\n",
    "class LinearRegressionLasso(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionLasso, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 12\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "lambda_lasso = 1  # L1 regularization parameter\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegressionLasso(input_size, output_size)\n",
    "\n",
    "# Define loss function (MSE loss with L1 regularization)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    # L1 regularization term\n",
    "    l1_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.norm(param, p=1)\n",
    "    \n",
    "    # Total loss with L1 regularization\n",
    "    loss += lambda_lasso * l1_reg\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can access the learned coefficients\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f'{name}: {param.data}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
