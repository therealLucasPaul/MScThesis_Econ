{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import log_hyperu as hyperu\n",
    "import tgr as tgr\n",
    "import math\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 10.6036\n",
      "Epoch [200/1000], Loss: 7.0338\n",
      "Epoch [300/1000], Loss: 6.6343\n",
      "Epoch [400/1000], Loss: 6.5833\n",
      "Epoch [500/1000], Loss: 6.5743\n",
      "Epoch [600/1000], Loss: 6.5747\n",
      "Epoch [700/1000], Loss: 6.5778\n",
      "Epoch [800/1000], Loss: 6.5804\n",
      "Epoch [900/1000], Loss: 6.5821\n",
      "Epoch [1000/1000], Loss: 6.5785\n",
      "With 1000 iterations, Regular LASSO Regularization took 1.3717 seconds. On this system, that is roughly 0.0013716657161712646 seconds per iteration.\n",
      "linear.weight: [[-0.08131898939609528, 0.11880242824554443, 5.130025863647461, 4.099651336669922, 0.0024799692910164595, -0.008265404962003231, 6.229494094848633, -0.03251353278756142, 0.006142516154795885, -0.11067549884319305]]\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "# Define your model\n",
    "starttime = time.time()\n",
    "class LinearRegressionLasso(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionLasso, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 10\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "lambda_lasso = 1 # L1 regularization parameter\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegressionLasso(input_size, output_size)\n",
    "\n",
    "# Define loss function (MSE loss with L1 regularization)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "\n",
    "    # Total loss with L1 regularization\n",
    "    l1_norm = sum(torch.linalg.norm(p, 1) for p in model.parameters())\n",
    "\n",
    "    loss = loss + lambda_lasso * l1_norm\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "endtime = time.time()\n",
    "print(f'With {num_epochs} iterations, Regular LASSO Regularization took {round(endtime-starttime,4)} seconds. On this system, that is roughly {(endtime-starttime)/num_epochs} seconds per iteration.')\n",
    "\n",
    "# After training, you can access the learned coefficients\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f'{name}: {param.data.tolist()}')\n",
    "        coefs_LASSO = param.data.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeValidationLoss(model, X_val, y_val):\n",
    "    model.eval()\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val).squeeze()\n",
    "        loss = mse_criterion(outputs, y_val)\n",
    "        total_loss = loss.item()\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "n_samples = [50]#[50, 100, 500, 1000]\n",
    "n_features = [10]#[3, 10, 25]\n",
    "n_nonzero = [0.5]#[0.1, 0.5, 0.9]\n",
    "\n",
    "scenario_combinations = list(itertools.product(n_samples, n_features, n_nonzero))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Optimal $\\lambda$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Scenario (50, 10, 0.5)\n",
      "--Started Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.0 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.0 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.01 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.01 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.02 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.02 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.03 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.03 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.04 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.04 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.05 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.05 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.06 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.06 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.07 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.07 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.08 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.08 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.09 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.09 of Run 1 of Scenario (50, 10, 0.5)!\n",
      "--Finished Run 1 of Scenario (50, 10, 0.5)!\n",
      "--Started Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.0 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.0 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.01 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.01 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.02 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.02 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.03 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.03 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.04 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.04 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.05 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.05 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.06 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.06 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.07 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.07 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.08 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.08 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.09 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.09 of Run 2 of Scenario (50, 10, 0.5)!\n",
      "--Finished Run 2 of Scenario (50, 10, 0.5)!\n",
      "--Started Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.0 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.0 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.01 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.01 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.02 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.02 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.03 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.03 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.04 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.04 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.05 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.05 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.06 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.06 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.07 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.07 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.08 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.08 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Started Reg-Strength 0.09 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "----Finished Reg-Strength 0.09 of Run 3 of Scenario (50, 10, 0.5)!\n",
      "--Finished Run 3 of Scenario (50, 10, 0.5)!\n",
      "Finished (50, 10, 0.5)\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Import Libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tgr as tgr\n",
    "import log_hyperu as hyperu\n",
    "\n",
    "# Step 0.1: Define necessary classes and functions\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_features, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_model(model, X_train, y_train, lr=0.01, n_epochs=1000):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train).squeeze()\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def lasso_loss(output, target, model, lasso_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    lasso_loss = lasso_reg_strength * torch.norm(model.linear.weight, 1)\n",
    "    return mse_loss + lasso_loss \n",
    "\n",
    "def ridge_loss(output, target, model, ridge_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    ridge_loss = ridge_reg_strength * torch.norm(model.linear.weight, 2)**2\n",
    "    return mse_loss + ridge_loss\n",
    "\n",
    "def tgr_loss(output, target, model, tgr_reg_strength, a, c, kappa):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    phi = torch.tensor((2*c)/((kappa**2)*a))\n",
    "    tgr_loss = tgr_reg_strength * torch.sum(-hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),(model.linear.weight**2)/(2*phi))+hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),torch.tensor([[0.0]])))\n",
    "    return mse_loss + tgr_loss\n",
    "\n",
    "def arctan_loss(output, target, model, arctan_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    arctan_loss = arctan_reg_strength*torch.sum((2/np.pi) * torch.arctan(torch.abs(model.linear.weight)))\n",
    "    return mse_loss + arctan_loss\n",
    "\n",
    "def gaussian_loss(output, target, model, gaussian_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    gaussian_loss = gaussian_reg_strength*torch.sum(1 - math.e**(-10*model.linear.weight**2))\n",
    "    return mse_loss + gaussian_loss\n",
    "\n",
    "# Step 1: Set random seed for reproducibility - (Iterate through multiple ones to increase statistical rigour)\n",
    "torch.manual_seed(123) \n",
    "np.random.seed(123) \n",
    "\n",
    "# Step 1.1: Define Lambda Grid and other key parameters\n",
    "lambda_grid = [0.01*i for i in range(0,10,1)] # From 0 to 1 with 0.01 steps\n",
    "n_epochs = 500\n",
    "n_runs = 3 # Set the time on how many optimal lambdas should be found for each sceario.\n",
    "metric = 'MSE' # Either MSE of Dev (Deviation for Variable Selection)\n",
    "optimal_lambda_list = list() # list storing the optimal values for each method and each scenario\n",
    "\n",
    "# Step 2: Iterate through scenarios\n",
    "for scen in scenario_combinations:\n",
    "    print(f'Started Scenario {scen}')\n",
    "    scen_samples = scen[0]\n",
    "    scen_features = scen[1]\n",
    "    scen_nonzero = math.ceil(scen[2]*scen[1])\n",
    "    \n",
    "    # Step 2.1: Create Sample Data Sets\n",
    "    # True coefficients with sparsity (many coefficients are zero)\n",
    "    true_coefficients = torch.zeros(scen_features)\n",
    "    true_coefficients[:scen_nonzero] = torch.randn(scen_nonzero)*5\n",
    "\n",
    "    # Generate features\n",
    "    X = torch.randn(scen_samples, scen_features)\n",
    "    for run in range(n_runs):\n",
    "        print(f'--Started Run {run+1} of Scenario {scen}!')\n",
    "\n",
    "        # Generate targets with noise\n",
    "        noise = torch.randn(scen_samples) * 0.5\n",
    "        y = X @ true_coefficients + noise\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Step 3: Train models\n",
    "        lasso_best_loss = 10000000000 # Hard Gecoded!\n",
    "        ridge_best_loss = 10000000000\n",
    "        tgr1_best_loss = 10000000000\n",
    "        tgr2_best_loss = 10000000000\n",
    "        tgr3_best_loss = 10000000000\n",
    "        arctan_best_loss = 10000000000\n",
    "        gaussian_best_loss = 10000000000\n",
    "\n",
    "        for reg_strength in lambda_grid:\n",
    "            print(f'----Started Reg-Strength {reg_strength} of Run {run+1} of Scenario {scen}!')\n",
    "            # Step 3.1: LASSO\n",
    "            lasso_model = LinearRegression(scen_features)\n",
    "            optimizer = torch.optim.SGD(lasso_model.parameters(), lr=0.01)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                lasso_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = lasso_model(X_train).squeeze()\n",
    "                loss = lasso_loss(outputs, y_train, lasso_model, reg_strength)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            val_loss = ComputeValidationLoss(lasso_model, X_test, y_test)\n",
    "            if val_loss < lasso_best_loss:\n",
    "                lasso_best_lamda = reg_strength\n",
    "                lasso_best_loss = val_loss\n",
    "\n",
    "            # Step 3.2: Ridge\n",
    "            ridge_model = LinearRegression(scen_features)\n",
    "            optimizer = torch.optim.SGD(ridge_model.parameters(), lr=0.01)\n",
    "            \n",
    "            for epoch in range(n_epochs):\n",
    "                ridge_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = ridge_model(X_train).squeeze()\n",
    "                loss = ridge_loss(outputs, y_train, ridge_model, reg_strength)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            val_loss = ComputeValidationLoss(ridge_model, X_test, y_test)\n",
    "            if val_loss < ridge_best_loss:\n",
    "                ridge_best_lamda = reg_strength\n",
    "                ridge_best_loss = val_loss\n",
    "                \n",
    "            # Step 3.3: TGR Setting 1\n",
    "            tgr_model1 = LinearRegression(scen_features)\n",
    "            optimizer = torch.optim.SGD(tgr_model1.parameters(), lr=0.01)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                tgr_model1.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = tgr_model1(X_train).squeeze()\n",
    "                loss = tgr_loss(outputs, y_train, tgr_model1, reg_strength, 0.75, 0.1, 2)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(tgr_model1.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            val_loss = ComputeValidationLoss(tgr_model1, X_test, y_test)\n",
    "\n",
    "            if val_loss < tgr1_best_loss:\n",
    "                tgr1_best_lamda = reg_strength\n",
    "                tgr1_best_loss = val_loss\n",
    "            \n",
    "            # Step 3.4: TGR Setting 2\n",
    "            tgr_model2 = LinearRegression(scen_features)\n",
    "            optimizer = torch.optim.SGD(tgr_model2.parameters(), lr=0.01)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                tgr_model2.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = tgr_model2(X_train).squeeze()\n",
    "                loss = tgr_loss(outputs, y_train, tgr_model2, reg_strength, 5, 0.01, 2)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(tgr_model2.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            val_loss = ComputeValidationLoss(tgr_model2, X_test, y_test)\n",
    "\n",
    "            if val_loss < tgr2_best_loss:\n",
    "                tgr2_best_lamda = reg_strength\n",
    "                tgr2_best_loss = val_loss\n",
    "\n",
    "            # Step 3.5: TGR Setting 3\n",
    "            tgr_model3 = LinearRegression(scen_features)\n",
    "            optimizer = torch.optim.SGD(tgr_model3.parameters(), lr=0.01)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                tgr_model3.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = tgr_model3(X_train).squeeze()\n",
    "                loss = tgr_loss(outputs, y_train, tgr_model3, reg_strength, 0.51, 0.01, 1)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(tgr_model3.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            val_loss = ComputeValidationLoss(tgr_model3, X_test, y_test)\n",
    "\n",
    "            if val_loss < tgr3_best_loss:\n",
    "                tgr3_best_lamda = reg_strength\n",
    "                tgr3_best_loss = val_loss\n",
    "        \n",
    "            # Step 3.6: Arctan\n",
    "            arctan_model = LinearRegression(scen_features)\n",
    "            optimizer = torch.optim.SGD(arctan_model.parameters(), lr=0.01)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                arctan_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = arctan_model(X_train).squeeze()\n",
    "                loss = arctan_loss(outputs, y_train, arctan_model, reg_strength)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(arctan_model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "            val_loss = ComputeValidationLoss(arctan_model, X_test, y_test)\n",
    "            \n",
    "            if val_loss < arctan_best_loss:\n",
    "                arctan_best_lamda = reg_strength\n",
    "                arctan_best_loss = val_loss\n",
    "                                \n",
    "            # Step 3.7: Gaussian\n",
    "            gaussian_model = LinearRegression(scen_features)\n",
    "            \n",
    "            for epoch in range(n_epochs):\n",
    "                gaussian_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = gaussian_model(X_train).squeeze()\n",
    "                loss = gaussian_loss(outputs, y_train, gaussian_model, reg_strength)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(gaussian_model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "            val_loss = ComputeValidationLoss(gaussian_model, X_test, y_test)\n",
    "                        \n",
    "            if val_loss < gaussian_best_loss:\n",
    "                gaussian_best_lamda = reg_strength\n",
    "                gaussian_best_loss = val_loss\n",
    "            print(f'----Finished Reg-Strength {reg_strength} of Run {run+1} of Scenario {scen}!')\n",
    "        print(f'--Finished Run {run+1} of Scenario {scen}!')\n",
    "        tmp = [scen, run+1, lasso_best_lamda, ridge_best_lamda, tgr1_best_lamda, tgr2_best_lamda, tgr3_best_lamda, arctan_best_lamda, gaussian_best_lamda]\n",
    "        optimal_lambda_list.append(tmp)\n",
    "    print(f'Finished {scen}')\n",
    "\n",
    "df_best_lambdas = pd.DataFrame(optimal_lambda_list, columns=[\"Scenario\", \"Run\", \"LASSO\", \"Ridge\", \"TGR Setting 1\", \"TGR Setting 2\", \"TGR Setting 3\", \"Arctan\", \"Gaussian\"])\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f\"optimal_lambda_{current_datetime}.xlsx\"\n",
    "\n",
    "# Export to Excel\n",
    "df_best_lambdas.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 3, 0.1)! 1 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 3, 0.5)! 2 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 3, 0.9)! 3 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 10, 0.1)! 4 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 10, 0.5)! 5 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 10, 0.9)! 6 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 25, 0.1)! 7 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 25, 0.5)! 8 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (50, 25, 0.9)! 9 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 3, 0.1)! 10 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 3, 0.5)! 11 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 3, 0.9)! 12 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 10, 0.1)! 13 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 10, 0.5)! 14 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 10, 0.9)! 15 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 25, 0.1)! 16 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 25, 0.5)! 17 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (100, 25, 0.9)! 18 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 3, 0.1)! 19 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 3, 0.5)! 20 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 3, 0.9)! 21 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 10, 0.1)! 22 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 10, 0.5)! 23 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 10, 0.9)! 24 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 25, 0.1)! 25 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 25, 0.5)! 26 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (500, 25, 0.9)! 27 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 3, 0.1)! 28 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 3, 0.5)! 29 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 3, 0.9)! 30 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 10, 0.1)! 31 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 10, 0.5)! 32 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 10, 0.9)! 33 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 25, 0.1)! 34 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 25, 0.5)! 35 of 36 finished!\n",
      "Run 1 of 25 finished!\n",
      "Run 2 of 25 finished!\n",
      "Run 3 of 25 finished!\n",
      "Run 4 of 25 finished!\n",
      "Run 5 of 25 finished!\n",
      "Run 6 of 25 finished!\n",
      "Run 7 of 25 finished!\n",
      "Run 8 of 25 finished!\n",
      "Run 9 of 25 finished!\n",
      "Run 10 of 25 finished!\n",
      "Run 11 of 25 finished!\n",
      "Run 12 of 25 finished!\n",
      "Run 13 of 25 finished!\n",
      "Run 14 of 25 finished!\n",
      "Run 15 of 25 finished!\n",
      "Run 16 of 25 finished!\n",
      "Run 17 of 25 finished!\n",
      "Run 18 of 25 finished!\n",
      "Run 19 of 25 finished!\n",
      "Run 20 of 25 finished!\n",
      "Run 21 of 25 finished!\n",
      "Run 22 of 25 finished!\n",
      "Run 23 of 25 finished!\n",
      "Run 24 of 25 finished!\n",
      "Run 25 of 25 finished!\n",
      "Finished Scenario (1000, 25, 0.9)! 36 of 36 finished!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(123) # 42\n",
    "np.random.seed(123) # 42\n",
    "\n",
    "# Step 0: Define necessary functions\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_features, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_model(model, X_train, y_train, lr=0.01, n_epochs=500):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train).squeeze()\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def lasso_loss(output, target, model, lasso_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    lasso_loss = lasso_reg_strength * torch.norm(model.linear.weight, 1)\n",
    "    return mse_loss + lasso_loss\n",
    "\n",
    "def ridge_loss(output, target, model, ridge_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    ridge_loss = ridge_reg_strength * torch.norm(model.linear.weight, 2)**2\n",
    "    return mse_loss + ridge_loss\n",
    "\n",
    "def tgr_loss(output, target, model, tgr_reg_strength, a, c, kappa):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    phi = torch.tensor((2*c)/((kappa**2)*a))\n",
    "    tgr_loss = tgr_reg_strength * torch.sum(-hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),(model.linear.weight**2)/(2*phi))+hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),torch.tensor([[0.0]])))\n",
    "    return mse_loss + tgr_loss\n",
    "\n",
    "def arctan_loss(output, target, model, arctan_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    arctan_loss = arctan_reg_strength*torch.sum((2/np.pi) * torch.arctan(torch.abs(model.linear.weight)))\n",
    "    return mse_loss + arctan_loss\n",
    "\n",
    "def gaussian_loss(output, target, model, gaussian_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    gaussian_loss = gaussian_reg_strength*torch.sum(1 - math.e**(-10*model.linear.weight**2))\n",
    "    return mse_loss + gaussian_loss\n",
    "\n",
    "# Step 1: Generate synthetic data using scenario\n",
    "n_epochs = 500\n",
    "runs = 25\n",
    "\n",
    "n_samples = [50, 100, 500, 1000]\n",
    "n_features = [3, 10, 25]\n",
    "n_nonzero = [0.1, 0.5, 0.9]\n",
    "\n",
    "scenario_combinations = list(itertools.product(n_samples, n_features, n_nonzero))\n",
    "\n",
    "# Make new simulation folder\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "simulation_folder_path = f'Simulation_{current_datetime}'\n",
    "os.makedirs(simulation_folder_path, exist_ok=True)\n",
    "\n",
    "counter=0\n",
    "for scen in scenario_combinations:\n",
    "    output_list = list() # Contains Tuples with (METHOD, LAMBDA, LOSS, COEFS)\n",
    "    counter = counter + 1\n",
    "    for run in range(runs):\n",
    "        n_samples = scen[0]\n",
    "        n_features = scen[1]\n",
    "        n_nonzero = math.ceil(scen[2]*scen[1])\n",
    "        # True coefficients with sparsity (many coefficients are zero)\n",
    "        true_coefficients = torch.zeros(n_features)\n",
    "        true_coefficients[:n_nonzero] = torch.randn(n_nonzero)\n",
    "\n",
    "        # Generate features\n",
    "        X = torch.randn(n_samples, n_features)\n",
    "\n",
    "        # Generate targets with noise\n",
    "        noise = torch.randn(n_samples) * 0.5\n",
    "        y = X @ true_coefficients + noise\n",
    "\n",
    "        # Step 2: Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Step 3: Implement OLS and Lasso regression using PyTorch\n",
    "\n",
    "        # Train OLS model\n",
    "        ols_model = LinearRegression(n_features)\n",
    "        ols_model = train_model(ols_model, X_train, y_train)\n",
    "        \n",
    "        # Train Lasso model\n",
    "        lasso_reg_strength = 0.13\n",
    "        lasso_model = LinearRegression(n_features)\n",
    "        optimizer = torch.optim.SGD(lasso_model.parameters(), lr=0.01)\n",
    "        for epoch in range(n_epochs):\n",
    "            lasso_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = lasso_model(X_train).squeeze()\n",
    "            loss = lasso_loss(outputs, y_train, lasso_model, lasso_reg_strength)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        # Train Rdige model\n",
    "        ridge_reg_strength = 0.58\n",
    "        ridge_model = LinearRegression(n_features)\n",
    "        optimizer = torch.optim.SGD(ridge_model.parameters(), lr=0.01)\n",
    "        for epoch in range(n_epochs):\n",
    "            ridge_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ridge_model(X_train).squeeze()\n",
    "            loss = ridge_loss(outputs, y_train, ridge_model, ridge_reg_strength)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Arctan Model\n",
    "        arctan_reg_strength = 0.18\n",
    "        arctan_model = LinearRegression(n_features)\n",
    "        for epoch in range(n_epochs):\n",
    "            arctan_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = arctan_model(X_train).squeeze()\n",
    "            loss = arctan_loss(outputs, y_train, arctan_model, arctan_reg_strength)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(arctan_model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Gaussian Model\n",
    "        gaussian_reg_strength = 0.89\n",
    "        gaussian_model = LinearRegression(n_features)\n",
    "        for epoch in range(n_epochs):\n",
    "            gaussian_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = gaussian_model(X_train).squeeze()\n",
    "            loss = gaussian_loss(outputs, y_train, gaussian_model, gaussian_reg_strength)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(gaussian_model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Train TGR Model - Setting 1\n",
    "        tgr_reg_strength = 0.02\n",
    "        tgr_model1 = LinearRegression(n_features)\n",
    "        optimizer = torch.optim.SGD(tgr_model1.parameters(), lr=0.01)\n",
    "        for epoch in range(n_epochs):\n",
    "            tgr_model1.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = tgr_model1(X_train).squeeze()\n",
    "            loss = tgr_loss(outputs, y_train, tgr_model1, tgr_reg_strength, 0.75, 0.1, 2)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(tgr_model1.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Train TGR Model - Setting 2\n",
    "        tgr_reg_strength = 0.04\n",
    "        tgr_model2 = LinearRegression(n_features)\n",
    "        optimizer = torch.optim.SGD(tgr_model2.parameters(), lr=0.01)\n",
    "        for epoch in range(n_epochs):\n",
    "            tgr_model2.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = tgr_model2(X_train).squeeze()\n",
    "            loss = tgr_loss(outputs, y_train, tgr_model2, tgr_reg_strength, 5, 0.01, 2)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(tgr_model2.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Train TGR Model - Setting 3\n",
    "        tgr_reg_strength = 0.13\n",
    "        tgr_model3 = LinearRegression(n_features)\n",
    "        optimizer = torch.optim.SGD(tgr_model3.parameters(), lr=0.01)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            tgr_model3.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = tgr_model3(X_train).squeeze()\n",
    "            loss = tgr_loss(outputs, y_train, tgr_model3, tgr_reg_strength, 0.51, 0.01, 1)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(tgr_model3.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Run {run+1} of {runs} finished!\")\n",
    "        # END RUNS LOOP\n",
    "    # END SCENARIO LOOP    \n",
    "\n",
    "    #df = pd.DataFrame(output_list, columns=[\"OLS\",\"LASSO\",\"Ridge\",\"TGR1\",\"Arctan\",\"Gaussian\",\"TGR2\",\"TGR3\"])\n",
    "    #file_name = f\"loss_scen_{n_samples}_{n_features}_{n_nonzero}.xlsx\"\n",
    "    #file_path = os.path.join(simulation_folder_path, file_name)\n",
    "    # Export to Excel\n",
    "    #df.to_excel(file_path, index=False)\n",
    "    #print(f\"Finished Scenario {scen}! {counter} of {len(scenario_combinations)} finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_plot = [col for col in df.columns if col != \"Arctan\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "boxprops = dict(linestyle='-', linewidth=2, color='royalblue')\n",
    "medianprops = dict(linestyle='-', linewidth=2.5, color='darkorange')\n",
    "\n",
    "plt.boxplot([df[col] for col in columns_to_plot], labels=columns_to_plot, boxprops=boxprops, medianprops=medianprops)\n",
    "plt.title('Distribution of Mean-Squared-Error (MSE) Rates \\n on Validation Sets for different Methods', fontsize=16)\n",
    "plt.xlabel('Regularization Method using optimal $\\\\lambda$', fontsize=10)\n",
    "plt.ylabel('Mean Squared Error (MSE) on Validation Set', fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid lines only for y-axis\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()  # Adjust layout to make room for labels\n",
    "ax.set_xticklabels(['OLS', 'LASSO', 'TGR Setting 1', 'TGR Setting 2', 'TGR Setting 3'])\n",
    "\n",
    "ax.set_xticks(major_ticks)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"021_simulation_figures/MSE_Pred_SampleScenario.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 0 of 20\n",
      "Finished run 1 of 20\n",
      "Finished run 2 of 20\n",
      "Finished run 3 of 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucas Paul\\Documents\\GitHub_Repos\\MScThesis_Econ\\02_simulation\\simulation_tgr.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#X11sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#X11sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(tgr_model2\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#X11sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#X11sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39m## TGR - Setting 3\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#X11sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m tgr_model3 \u001b[39m=\u001b[39m LinearRegression(n_features)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:368\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprofile_hook_step\u001b[39m(func: Callable[_P, R]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Callable[_P, R]:\n\u001b[1;32m--> 368\u001b[0m     \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    369\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: _P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: _P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m R:\n\u001b[0;32m    370\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[0;32m    371\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m cast(Optimizer, \u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Absolut Deviation Plot\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(123) # 42\n",
    "np.random.seed(123) # 42\n",
    "\n",
    "# Step 1: Generate synthetic data\n",
    "n_samples = 100\n",
    "n_features = 25\n",
    "n_nonzero = 3\n",
    "runs = 20\n",
    "n_epochs = 250\n",
    "\n",
    "ols_dev_list = list()\n",
    "lasso_dev_list = list()\n",
    "tgr_dev_S1 = list()\n",
    "tgr_dev_S2 = list()\n",
    "tgr_dev_S3 = list()\n",
    "\n",
    "\n",
    "for run in range(runs):\n",
    "    # True coefficients with sparsity (many coefficients are zero)\n",
    "    true_coefficients = torch.zeros(n_features)\n",
    "    true_coefficients[:n_nonzero] = torch.randn(n_nonzero)\n",
    "\n",
    "    # Generate features\n",
    "    X = torch.randn(n_samples, n_features)\n",
    "\n",
    "    # Generate targets with noise\n",
    "    noise = torch.randn(n_samples) * 0.5\n",
    "    y = X @ true_coefficients + noise\n",
    "\n",
    "    # Step 2: Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 3: Implement OLS and Lasso regression using PyTorch\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, n_features):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(n_features, 1, bias=False)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            return self.linear(x)\n",
    "\n",
    "    def train_model(model, X_train, y_train, lr=0.01, n_epochs=250):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train).squeeze()\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        return model\n",
    "\n",
    "    # Train OLS model\n",
    "    ols_model = LinearRegression(n_features)\n",
    "    ols_model = train_model(ols_model, X_train, y_train)\n",
    "\n",
    "    # Train Lasso model\n",
    "    lasso_model = LinearRegression(n_features)\n",
    "    lasso_reg_strength = 0.13 # Regularization strength\n",
    "\n",
    "    def lasso_loss(output, target, model, lasso_reg_strength):\n",
    "        mse_loss = nn.MSELoss()(output, target)\n",
    "        lasso_loss = lasso_reg_strength * torch.norm(model.linear.weight, 1)\n",
    "        return mse_loss + lasso_loss\n",
    "\n",
    "    optimizer = torch.optim.SGD(lasso_model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        lasso_model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = lasso_model(X_train).squeeze()\n",
    "        loss = lasso_loss(outputs, y_train, lasso_model, lasso_reg_strength)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Train TGR Model\n",
    "    def tgr_loss(output, target, model, tgr_reg_strength, a, c, kappa):\n",
    "        mse_loss = nn.MSELoss()(output, target)\n",
    "        phi = torch.tensor((2*c)/((kappa**2)*a))\n",
    "        tgr_loss = tgr_reg_strength * torch.sum(-hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),(model.linear.weight**2)/(2*phi))+hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),torch.tensor([[0.0]])))\n",
    "\n",
    "        return mse_loss + tgr_loss\n",
    "\n",
    "    ## TGR - Setting 1\n",
    "    tgr_model1 = LinearRegression(n_features)\n",
    "    optimizer = torch.optim.SGD(tgr_model1.parameters(), lr=0.01)\n",
    "    \n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        tgr_model1.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = tgr_model1(X_train).squeeze()\n",
    "        loss = tgr_loss(outputs, y_train, tgr_model1, 0.03, 0.75, 0.1, 2)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(tgr_model1.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "    ## TGR - Setting 2\n",
    "    tgr_model2 = LinearRegression(n_features)\n",
    "    optimizer = torch.optim.SGD(tgr_model2.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        tgr_model2.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = tgr_model2(X_train).squeeze()\n",
    "        loss = tgr_loss(outputs, y_train, tgr_model2, 0.04, 5, 0.01, 2)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(tgr_model2.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    ## TGR - Setting 3\n",
    "    tgr_model3 = LinearRegression(n_features)\n",
    "    optimizer = torch.optim.SGD(tgr_model3.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        tgr_model3.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = tgr_model3(X_train).squeeze()\n",
    "        loss = tgr_loss(outputs, y_train, tgr_model3, 0.08, 0.51, 0.001, 1)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(tgr_model3.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Step 5: Plot the true and estimated coefficients\n",
    "\n",
    "    # Get the estimated coefficients\n",
    "    ols_coefficients = ols_model.linear.weight.detach().numpy().flatten()\n",
    "    lasso_coefficients = lasso_model.linear.weight.detach().numpy().flatten()\n",
    "    #arctan_coefficients = arctan_model.linear.weight.detach().numpy.flatten()\n",
    "    tgr_coefficients_S1 = tgr_model1.linear.weight.detach().numpy().flatten()\n",
    "    tgr_coefficients_S2 = tgr_model2.linear.weight.detach().numpy().flatten()\n",
    "    tgr_coefficients_S3 = tgr_model3.linear.weight.detach().numpy().flatten()\n",
    "    true_coefficients_np = true_coefficients.numpy()\n",
    "\n",
    "    # Get absolute deviation\n",
    "    ols_dev_list.append(sum(abs(ols_coefficients-true_coefficients_np)))\n",
    "    lasso_dev_list.append(sum(abs(lasso_coefficients-true_coefficients_np)))\n",
    "    tgr_dev_S1.append(sum(abs(tgr_coefficients_S1 - true_coefficients_np)))\n",
    "    tgr_dev_S2.append(sum(abs(tgr_coefficients_S2 - true_coefficients_np)))\n",
    "    tgr_dev_S3.append(sum(abs(tgr_coefficients_S3 - true_coefficients_np)))\n",
    "    \n",
    "    print(f'Finished run {run} of {runs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(ols_dev_list)\n",
    "#print(lasso_dev_list)\n",
    "#print(tgr_dev_list)\n",
    "\n",
    "# Combine data into a list\n",
    "data = [ols_dev_list, lasso_dev_list, tgr_dev_S1, tgr_dev_S2, tgr_dev_S3]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot box plots\n",
    "ax.boxplot(data, patch_artist=True, notch=True,\n",
    "            boxprops=dict(facecolor='skyblue', color='blue'),\n",
    "            capprops=dict(color='blue'),\n",
    "            whiskerprops=dict(color='blue'),\n",
    "            flierprops=dict(color='blue', markeredgecolor='blue'),\n",
    "            medianprops=dict(color='red'))\n",
    "plt.title('Distribution of the Sum of the Absolute Deviations \\nof the Estimates to the True Coefficients')\n",
    "ax.set_xlabel('Regularization Method')\n",
    "ax.set_ylabel('Absolute Deviation')\n",
    "ax.set_xticklabels(['OLS', 'LASSO', 'TGR Setting 1', 'TGR Setting 2', 'TGR Setting 3'])\n",
    "major_ticks = np.arange(1, 6, 1)\n",
    "ax.set_xticks(major_ticks)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot the true and estimated coefficients\n",
    "\n",
    "# Get the estimated coefficients\n",
    "#ols_coefficients = ols_model.linear.weight.detach().numpy().flatten()\n",
    "#lasso_coefficients = lasso_model.linear.weight.detach().numpy().flatten()\n",
    "#tgr_coefficients_LASSO = tgr_model1_LASSO.linear.weight.detach().numpy().flatten()\n",
    "#tgr_coefficients_Special = tgr_model2_Special.linear.weight.detach().numpy().flatten()\n",
    "#arctan_coefficients = arctan_model.linear.weight.detach().numpy().flatten()\n",
    "#true_coefficients_np = true_coefficients.numpy()\n",
    "\n",
    "# Plotting\n",
    "#fig = plt.figure(figsize=(12, 6))\n",
    "#ax = fig.add_subplot(1, 1, 1)\n",
    "#plt.plot(true_coefficients_np, label='True Coefficients', marker='o')\n",
    "#plt.plot(ols_coefficients, label='OLS Estimated', marker='x')\n",
    "#plt.plot(lasso_coefficients, label='LASSO Estimated', marker='.')\n",
    "#plt.plot(tgr_coefficients_LASSO, label='TGR Estimated - LASSO Replica', marker='.')\n",
    "#plt.plot(tgr_coefficients_Special, label='TGR Estimated - Example', marker='.')\n",
    "#plt.plot(arctan_coefficients, label='Arctan Estimated', marker='.')\n",
    "#plt.xlabel('Feature Index')\n",
    "#plt.ylabel('Coefficient Value')\n",
    "#plt.title('True vs Estimated Coefficients')\n",
    "\n",
    "#major_ticks = np.arange(0, 10, 1)\n",
    "#ax.set_xticks(major_ticks)\n",
    "\n",
    "#plt.legend()\n",
    "#plt.grid(True)\n",
    "#plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Approach to Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special as sp\n",
    "\n",
    "\"\"\"Unfortunately, it appears that not all approximations of the hyperu function as x -> 0 \n",
    "are implemented in the scipy library. As such, this is an implementation of those \n",
    "appearing in the DLMF (https://dlmf.nist.gov/13.2#iii).\n",
    "a, b, and z are all tensors of the same shape. The function returns a tensor of the same shape.\n",
    "\"\"\"\n",
    "def robust_hyperu(a, b, z):\n",
    "    res = torch.zeros_like(z)\n",
    "    res.fill_(np.nan)\n",
    "    small_z = torch.abs(z) < 1e-9\n",
    "\n",
    "    # Approximation for small z and b > 2\n",
    "    res = torch.where(torch.logical_and(small_z, b > 2), \n",
    "                        torch.exp(torch.lgamma(b - 1) - torch.lgamma(a) + (1 - b) * torch.log(z)),\n",
    "                        res)\n",
    "\n",
    "    # Approximation for small z and b = 2\n",
    "    res = torch.where(torch.logical_and(small_z, b == 2),\n",
    "                        torch.exp(-torch.lgamma(a) - torch.log(z)),\n",
    "                        res)\n",
    "\n",
    "    # Approximation for small z and 1 < b < 2\n",
    "    res = torch.where(torch.logical_and(torch.logical_and(small_z, b < 2), b > 1),\n",
    "                        torch.exp(torch.lgamma(b - 1) - torch.lgamma(a) + (1 - b) * torch.log(z)) +\n",
    "                        torch.exp(-torch.lgamma(1 - b) - torch.lgamma(a - b +1)),\n",
    "                        res)\n",
    "\n",
    "    # Approximation for small z and b = 1\n",
    "    res = torch.where(torch.logical_and(small_z, b == 1),\n",
    "                        -torch.exp(-torch.lgamma(a) - torch.log(z + torch.digamma(a) + 0.57721566490153286060651209008240243)),\n",
    "                        res)\n",
    "\n",
    "    # Approximation for small z and 0 < b < 1\n",
    "    res = torch.where(torch.logical_and(torch.logical_and(small_z, b < 1), b > 0),\n",
    "                        torch.exp(torch.lgamma(1 - b) - torch.lgamma(a - b + 1)),\n",
    "                        res)\n",
    "\n",
    "    # Approximation for small z and b = 0\n",
    "    res = torch.where(torch.logical_and(small_z, b == 0),\n",
    "                        torch.exp(-torch.lgamma(a + 1)),\n",
    "                        res)\n",
    "\n",
    "    # Approximation for small z and b < 0\n",
    "    res = torch.where(torch.logical_and(small_z, b < 0),\n",
    "                        torch.exp(torch.lgamma(1 - b) - torch.lgamma(a - b + 1)),\n",
    "                        res)\n",
    "\n",
    "    # Fill up all where no special case applies\n",
    "    res = torch.where(torch.isnan(res), sp.hyperu(a, b, z), res)\n",
    "    return(res)\n",
    "\n",
    "\"\"\"Then, define the log_hyperu function that can be used in autograd\n",
    "a, b, and x are all tensors of the same shape. The function returns a tensor of the same shape.\n",
    "Currently, the function is not differentiable with respect to a and b. I'm not entirely sure this is possible anyways \n",
    "\"\"\"\n",
    "class log_hyperu(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b, x):\n",
    "        u_res = robust_hyperu(a, b, x)\n",
    "        result = torch.log(u_res)\n",
    "\n",
    "        ctx.mark_non_differentiable(a)\n",
    "        ctx.mark_non_differentiable(b)\n",
    "\n",
    "        ctx.save_for_backward(a, b, x, u_res)\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        a, b, x, u_res = ctx.saved_tensors\n",
    "        grad_x = grad_output * (-a * torch.div(robust_hyperu(a + 1, b + 1, x), u_res))\n",
    "\n",
    "        return None, None, grad_x\n",
    "    \n",
    "# Alias the apply method:\n",
    "log_hyperu = log_hyperu.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import multiprocessing as mp # Mutli-Threading\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "#import log_hyperu as hyperu\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "# Step 0: Define necessary functions\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_features, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_model(model, X_train, y_train, loss_fn, lambda_val=None, n_epochs=500, lr=0.01):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr) # Stochastic Gradient Descent\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train).squeeze()\n",
    "        if lambda_val is not None:\n",
    "            loss = loss_fn(outputs, y_train, model, lambda_val)\n",
    "        else:\n",
    "            loss = loss_fn(outputs, y_train)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def lasso_loss(output, target, model, lasso_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    lasso_loss = lasso_reg_strength * torch.norm(model.linear.weight, 1)\n",
    "    return mse_loss + lasso_loss\n",
    "\n",
    "def ridge_loss(output, target, model, ridge_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    ridge_loss = ridge_reg_strength * torch.norm(model.linear.weight, 2)**2\n",
    "    return mse_loss + ridge_loss\n",
    "\n",
    "def tgr_loss(output, target, model, tgr_reg_strength, a, c, kappa):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    phi = torch.tensor((2*c)/((kappa**2)*a))\n",
    "    tgr_loss = tgr_reg_strength * torch.sum(-log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),(model.linear.weight**2)/(2*phi))) # +log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),torch.tensor([[0.0]]))\n",
    "    return mse_loss + tgr_loss\n",
    "\n",
    "def arctan_loss(output, target, model, arctan_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    arctan_loss = arctan_reg_strength*torch.sum((2/np.pi) * torch.arctan(torch.abs(model.linear.weight)))\n",
    "    return mse_loss + arctan_loss\n",
    "\n",
    "def gaussian_loss(output, target, model, gaussian_reg_strength):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    gaussian_loss = gaussian_reg_strength*torch.sum(1 - math.e**(-10*model.linear.weight**2))\n",
    "    return mse_loss + gaussian_loss\n",
    "\n",
    "def cross_validate_lambda(model_class, loss_fn, lambda_values, X_train, y_train, model_name, n_epochs=300):\n",
    "    kf = KFold(n_splits=5) # 5-fold CV\n",
    "    best_lambda = None\n",
    "    best_loss = float('inf') # Hard Gecoded to start the loss somewhere\n",
    "    \n",
    "    for lambda_val in lambda_values:\n",
    "        fold_losses = []\n",
    "        #print(f'Tested $\\\\lambda$ values {lambda_val} for {model_name}.')\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "            y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "            model = model_class(X_tr.shape[1])\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "            \n",
    "            for epoch in range(n_epochs):\n",
    "                model.train()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_tr).squeeze()\n",
    "                loss = loss_fn(outputs, y_tr, model, lambda_val)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Compute validation loss\n",
    "            fold_losses.append(nn.MSELoss()(model(X_val).squeeze(), y_val).item())\n",
    "        \n",
    "        avg_val_loss = np.mean(fold_losses)\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_lambda = lambda_val\n",
    "    print(f'Best Lambda for {model_name} is {best_lambda}.')\n",
    "    return best_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(scen,simulation_folder_path):\n",
    "    output_list = list()  # Contains Tuples with (METHOD, LAMBDA, LOSS, COEFS)\n",
    "    \n",
    "    n_samples = scen[0]\n",
    "    n_features = scen[1]\n",
    "    n_nonzero = math.ceil(scen[2] * scen[1])\n",
    "    for run in range(runs):\n",
    "\n",
    "        # True coefficients with sparsity (many coefficients are zero)\n",
    "        true_coefficients = torch.zeros(n_features)\n",
    "        true_coefficients[:n_nonzero] = 3 #torch.randn(n_nonzero) - Heterogenuous effects or just 3 like in WangEtAl(2020)\n",
    "\n",
    "        # Generate features\n",
    "        X = torch.randn(n_samples, n_features)\n",
    "        \n",
    "        # Signal To Noise Ratio (See Wang (2020)) - Get a descent ratio between noise and signal - Set mutiple values for more extensive analsyis\n",
    "        SNR = 1\n",
    "        signal_power = (X @ true_coefficients).var() * n_samples\n",
    "        noise_variance = signal_power / (n_samples * SNR ** 2)\n",
    "        noise_std = math.sqrt(noise_variance)\n",
    "        noise = torch.randn(n_samples) * noise_std\n",
    "        \n",
    "        # Generate targets with noise\n",
    "        y = X @ true_coefficients + noise\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Define lambda ranges for cross-validation\n",
    "        lambda_values_lasso = [0.001, 0.01, 0.1, 0.25,0.4,0.5, 0.6, 0.75, 0.9, 0.95] ## From 0 to 1 with 0.01 steps\n",
    "        lambda_values_ridge = [0.001, 0.01, 0.1, 0.25,0.4,0.5, 0.6, 0.75, 0.9, 0.95]  #[0.05*i for i in range(0,20,1)]\n",
    "        lambda_values_tgr =  [0.001, 0.01, 0.1, 0.25,0.4,0.5, 0.6, 0.75, 0.9, 0.95]  #[0.05*i for i in range(0,20,1)]\n",
    "        lambda_values_arctan =  [0.001, 0.01, 0.1, 0.25,0.4,0.5, 0.6, 0.75, 0.9, 0.95]  #[0.05*i for i in range(0,20,1)]\n",
    "        lambda_values_gaussian =  [0.001, 0.01, 0.1, 0.25,0.4,0.5, 0.6, 0.75, 0.9, 0.95]  #[0.05*i for i in range(0,20,1)]\n",
    "\n",
    "        # Train OLS model\n",
    "        ols_model = LinearRegression(n_features)\n",
    "        ols_model = train_model(ols_model, X_train, y_train, nn.MSELoss())\n",
    "        ols_loss = nn.MSELoss()(ols_model(X_test).squeeze(), y_test).item()\n",
    "        output_list.append(['OLS', run+1, 0, ols_loss, ols_model.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of OLS, scenario {scen}.')\n",
    "\n",
    "        # Find best lambda for LASSO\n",
    "        best_lambda_lasso = cross_validate_lambda(LinearRegression, lasso_loss, lambda_values_lasso, X_train, y_train, \"LASSO\")\n",
    "        lasso_model = train_model(LinearRegression(n_features), X_train, y_train, lasso_loss, best_lambda_lasso)\n",
    "        output_list.append(['LASSO', run+1, best_lambda_lasso, nn.MSELoss()(lasso_model(X_test).squeeze(), y_test).item(), lasso_model.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of LASSO, scenario {scen}.')\n",
    "        \n",
    "        # Find best lambda for Ridge\n",
    "        best_lambda_ridge = cross_validate_lambda(LinearRegression, ridge_loss, lambda_values_ridge, X_train, y_train, \"Ridge\")\n",
    "        ridge_model = train_model(LinearRegression(n_features), X_train, y_train, ridge_loss, best_lambda_ridge)\n",
    "        output_list.append(['Ridge', run+1, best_lambda_ridge, nn.MSELoss()(ridge_model(X_test).squeeze(), y_test).item(), ridge_model.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of Ridge, scenario {scen}.')\n",
    "\n",
    "        # Find best lambda for Arctan\n",
    "        best_lambda_arctan = cross_validate_lambda(LinearRegression, arctan_loss, lambda_values_arctan, X_train, y_train, \"Arctan\")\n",
    "        arctan_model = train_model(LinearRegression(n_features), X_train, y_train, arctan_loss, best_lambda_arctan)\n",
    "        output_list.append(['Arctan', run+1, best_lambda_arctan, nn.MSELoss()(arctan_model(X_test).squeeze(), y_test).item(), arctan_model.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of Arctan, scenario {scen}.')\n",
    "\n",
    "        # Find best lambda for Gaussian\n",
    "        best_lambda_gaussian = cross_validate_lambda(LinearRegression, gaussian_loss, lambda_values_gaussian, X_train, y_train, \"Gaussian\")\n",
    "        gaussian_model = train_model(LinearRegression(n_features), X_train, y_train, gaussian_loss, best_lambda_gaussian)\n",
    "        output_list.append(['Gaussian', run+1, best_lambda_gaussian, nn.MSELoss()(gaussian_model(X_test).squeeze(), y_test).item(), gaussian_model.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of Gaussian, scenario {scen}.')\n",
    "        \n",
    "        # Train TGR Models with specific settings\n",
    "        best_lambda_tgr1 = cross_validate_lambda(LinearRegression, lambda output, target, model, lambda_val: tgr_loss(output, target, model, lambda_val, 0.75, 0.1, 2), lambda_values_tgr, X_train, y_train, \"TGR Setting 1\")\n",
    "        tgr_model1 = train_model(LinearRegression(n_features), X_train, y_train, lambda output, target, model, lambda_val: tgr_loss(output, target, model, lambda_val, 0.75, 0.1, 2), best_lambda_tgr1)\n",
    "        output_list.append(['TGR Setting 1', run+1, best_lambda_tgr1, nn.MSELoss()(tgr_model1(X_test).squeeze(), y_test).item(), tgr_model1.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of TGR 1, scenario {scen}.')\n",
    "\n",
    "        best_lambda_tgr2 = cross_validate_lambda(LinearRegression, lambda output, target, model, lambda_val: tgr_loss(output, target, model, lambda_val, 5, 0.01, 2), lambda_values_tgr, X_train, y_train, \"TGR Setting 2\")\n",
    "        tgr_model2 = train_model(LinearRegression(n_features), X_train, y_train, lambda output, target, model, lambda_val: tgr_loss(output, target, model, lambda_val, 5, 0.01, 2), best_lambda_tgr2)\n",
    "        output_list.append(['TGR Setting 2', run+1, best_lambda_tgr2, nn.MSELoss()(tgr_model2(X_test).squeeze(), y_test).item(), tgr_model2.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of TGR 2, scenario {scen}.')\n",
    "\n",
    "        best_lambda_tgr3 = cross_validate_lambda(LinearRegression, lambda output, target, model, lambda_val: tgr_loss(output, target, model, lambda_val, 0.51, 0.01, 1), lambda_values_tgr, X_train, y_train, \"TGR Setting 3\")\n",
    "        tgr_model3 = train_model(LinearRegression(n_features), X_train, y_train, lambda output, target, model, lambda_val: tgr_loss(output, target, model, lambda_val, 0.51, 0.01, 1), best_lambda_tgr3)\n",
    "        output_list.append(['TGR Setting 3', run+1, best_lambda_tgr3, nn.MSELoss()(tgr_model3(X_test).squeeze(), y_test).item(), tgr_model3.linear.weight.detach().numpy()[0].tolist()])\n",
    "        print(f'Finished run {run+1} of TGR 3, scenario {scen}.')\n",
    "\n",
    "        print(f\"-- Run {run + 1} of {runs} finished in scenario {scen}!\")\n",
    "        # END RUNS LOOP\n",
    "        \n",
    "    df = pd.DataFrame(output_list, columns=['Name', 'Run', 'Lambda', 'Loss', 'Weights'])\n",
    "    scenario_str = f\"{n_samples}_{n_features}_{n_nonzero}\"\n",
    "    file_name = f\"{scenario_str}.xlsx\"\n",
    "    file_path = os.path.join(simulation_folder_path, file_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "    # End Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 1 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 1 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 1 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 1 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 1 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 1 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 1 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 1 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 2 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 2 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.1.\n",
      "Finished run 2 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 2 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 2 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 2 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 2 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 2 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 2 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 3 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 3 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 3 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 3 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 3 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 3 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 3 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 3 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 3 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 4 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 4 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 4 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 4 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.9.\n",
      "Finished run 4 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 4 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 4 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 4 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 4 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 5 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 5 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 5 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 5 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 5 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 5 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 5 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 5 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 5 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 6 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 6 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 6 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 6 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 6 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 6 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 6 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 6 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 6 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 7 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 7 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 7 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 7 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 7 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 7 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 7 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 7 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 7 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 8 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.1.\n",
      "Finished run 8 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 8 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 8 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 8 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 8 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 8 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 8 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 8 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 9 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 9 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 9 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 9 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 9 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 9 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.75.\n",
      "Finished run 9 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 9 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 9 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 10 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 10 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 10 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 10 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 10 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 10 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 10 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 10 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 10 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 11 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 11 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 11 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 11 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.95.\n",
      "Finished run 11 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 11 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 11 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 11 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 11 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 12 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 12 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 12 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 12 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.95.\n",
      "Finished run 12 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 12 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 12 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 12 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 12 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 13 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 13 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 13 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 13 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.95.\n",
      "Finished run 13 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 13 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 13 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 13 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 13 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 14 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 14 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 14 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 14 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 14 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 14 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 14 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 14 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 14 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished run 15 of OLS, scenario (250, 10, 0.1).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 15 of LASSO, scenario (250, 10, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 15 of Ridge, scenario (250, 10, 0.1).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 15 of Arctan, scenario (250, 10, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 15 of Gaussian, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 15 of TGR 1, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 15 of TGR 2, scenario (250, 10, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 15 of TGR 3, scenario (250, 10, 0.1).\n",
      "-- Run 15 of 15 finished in scenario (250, 10, 0.1)!\n",
      "Finished Scenario (250, 10, 0.1)!\n",
      "Finished run 1 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 1 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 1 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 1 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.95.\n",
      "Finished run 1 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 1 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 1 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 1 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 1 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 2 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.01.\n",
      "Finished run 2 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 2 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 2 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 2 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 2 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 2 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 2 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 2 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 3 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.1.\n",
      "Finished run 3 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 3 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 3 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 3 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 3 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 3 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 3 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 3 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 4 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.1.\n",
      "Finished run 4 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 4 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 4 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 4 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 4 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 4 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 4 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 4 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 5 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.6.\n",
      "Finished run 5 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 5 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.001.\n",
      "Finished run 5 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 5 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 5 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 5 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 5 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 5 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 6 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 6 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 6 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 6 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 6 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 6 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 6 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 6 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 6 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 7 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 7 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.75.\n",
      "Finished run 7 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 7 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 7 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 7 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 7 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 7 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 7 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 8 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 8 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 8 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.25.\n",
      "Finished run 8 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 8 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 8 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 8 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 8 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 8 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 9 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.01.\n",
      "Finished run 9 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 9 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 9 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 9 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 9 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 9 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 9 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 9 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 10 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 10 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.75.\n",
      "Finished run 10 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 10 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 10 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 10 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 10 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 10 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 10 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 11 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.9.\n",
      "Finished run 11 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 11 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 11 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.6.\n",
      "Finished run 11 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 11 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 11 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 11 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 11 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 12 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.9.\n",
      "Finished run 12 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.1.\n",
      "Finished run 12 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 12 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 12 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 12 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 12 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 12 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 12 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 13 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 13 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 13 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.9.\n",
      "Finished run 13 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 13 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 13 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 13 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 13 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 13 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 14 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 14 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.4.\n",
      "Finished run 14 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 14 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 14 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 14 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 14 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 14 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 14 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished run 15 of OLS, scenario (250, 10, 0.5).\n",
      "Best Lambda for LASSO is 0.95.\n",
      "Finished run 15 of LASSO, scenario (250, 10, 0.5).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 15 of Ridge, scenario (250, 10, 0.5).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 15 of Arctan, scenario (250, 10, 0.5).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 15 of Gaussian, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 15 of TGR 1, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 15 of TGR 2, scenario (250, 10, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 15 of TGR 3, scenario (250, 10, 0.5).\n",
      "-- Run 15 of 15 finished in scenario (250, 10, 0.5)!\n",
      "Finished Scenario (250, 10, 0.5)!\n",
      "Finished run 1 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.1.\n",
      "Finished run 1 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 1 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 1 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 1 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 1 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 1 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 1 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 1 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 2 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 2 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 2 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 2 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 2 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 2 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 2 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 2 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 2 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 3 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.95.\n",
      "Finished run 3 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.1.\n",
      "Finished run 3 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 3 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 3 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 3 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 3 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 3 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 3 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 4 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 4 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.75.\n",
      "Finished run 4 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 4 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.01.\n",
      "Finished run 4 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 4 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 4 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 4 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 4 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 5 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.01.\n",
      "Finished run 5 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 5 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.25.\n",
      "Finished run 5 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.01.\n",
      "Finished run 5 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 5 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 5 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 5 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 5 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 6 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 6 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 6 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 6 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.01.\n",
      "Finished run 6 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 6 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 6 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 6 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 6 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 7 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 7 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.95.\n",
      "Finished run 7 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 7 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 7 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 7 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 7 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 7 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 7 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 8 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 8 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.1.\n",
      "Finished run 8 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 8 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 8 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 8 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 8 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 8 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 8 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 9 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 9 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.4.\n",
      "Finished run 9 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.9.\n",
      "Finished run 9 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 9 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 9 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 9 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 9 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 9 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 10 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 10 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 10 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 10 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 10 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 10 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 10 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 10 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 10 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 11 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 11 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 11 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 11 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 11 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 11 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 11 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 11 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 11 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 12 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 12 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 12 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 12 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 12 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 12 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 12 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 12 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 12 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 13 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 13 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 13 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.001.\n",
      "Finished run 13 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 13 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 13 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 13 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 13 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 13 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 14 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 14 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 14 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 14 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 14 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 14 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 14 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 14 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 14 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished run 15 of OLS, scenario (250, 10, 0.9).\n",
      "Best Lambda for LASSO is 0.01.\n",
      "Finished run 15 of LASSO, scenario (250, 10, 0.9).\n",
      "Best Lambda for Ridge is 0.4.\n",
      "Finished run 15 of Ridge, scenario (250, 10, 0.9).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 15 of Arctan, scenario (250, 10, 0.9).\n",
      "Best Lambda for Gaussian is 0.01.\n",
      "Finished run 15 of Gaussian, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 15 of TGR 1, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 15 of TGR 2, scenario (250, 10, 0.9).\n",
      "Best Lambda for TGR Setting 3 is 0.1.\n",
      "Finished run 15 of TGR 3, scenario (250, 10, 0.9).\n",
      "-- Run 15 of 15 finished in scenario (250, 10, 0.9)!\n",
      "Finished Scenario (250, 10, 0.9)!\n",
      "Finished run 1 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.6.\n",
      "Finished run 1 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 1 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 1 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 1 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 1 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 1 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 1 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 1 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 2 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 2 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 2 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.6.\n",
      "Finished run 2 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.9.\n",
      "Finished run 2 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 2 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 2 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 2 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 2 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 3 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.6.\n",
      "Finished run 3 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 3 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 3 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 3 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 3 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 3 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 3 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 3 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 4 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 4 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.1.\n",
      "Finished run 4 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 4 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 4 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 4 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 4 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 4 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 4 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 5 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 5 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 5 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.9.\n",
      "Finished run 5 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.6.\n",
      "Finished run 5 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 5 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 5 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 5 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 5 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 6 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.9.\n",
      "Finished run 6 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 6 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.9.\n",
      "Finished run 6 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.9.\n",
      "Finished run 6 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 6 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 6 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 6 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 6 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 7 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 7 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 7 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 7 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.6.\n",
      "Finished run 7 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 7 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 7 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 7 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 7 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 8 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.9.\n",
      "Finished run 8 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 8 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 8 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.9.\n",
      "Finished run 8 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 8 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 8 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 8 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 8 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 9 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.6.\n",
      "Finished run 9 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 9 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 9 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 9 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 9 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 9 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 9 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 9 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 10 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.6.\n",
      "Finished run 10 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 10 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 10 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.75.\n",
      "Finished run 10 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 10 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 10 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 10 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 10 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 11 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.1.\n",
      "Finished run 11 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 11 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.75.\n",
      "Finished run 11 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 11 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 11 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 11 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 11 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 11 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 12 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 12 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.9.\n",
      "Finished run 12 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 12 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.6.\n",
      "Finished run 12 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 12 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 12 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 12 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 12 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 13 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 13 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.75.\n",
      "Finished run 13 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 13 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.9.\n",
      "Finished run 13 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 13 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 13 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 13 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 13 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 14 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.6.\n",
      "Finished run 14 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 14 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 14 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.6.\n",
      "Finished run 14 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 14 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.5.\n",
      "Finished run 14 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 14 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 14 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished run 15 of OLS, scenario (250, 50, 0.1).\n",
      "Best Lambda for LASSO is 0.95.\n",
      "Finished run 15 of LASSO, scenario (250, 50, 0.1).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 15 of Ridge, scenario (250, 50, 0.1).\n",
      "Best Lambda for Arctan is 0.95.\n",
      "Finished run 15 of Arctan, scenario (250, 50, 0.1).\n",
      "Best Lambda for Gaussian is 0.6.\n",
      "Finished run 15 of Gaussian, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 15 of TGR 1, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 15 of TGR 2, scenario (250, 50, 0.1).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 15 of TGR 3, scenario (250, 50, 0.1).\n",
      "-- Run 15 of 15 finished in scenario (250, 50, 0.1)!\n",
      "Finished Scenario (250, 50, 0.1)!\n",
      "Finished run 1 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 1 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 1 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 1 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.01.\n",
      "Finished run 1 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 1 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 1 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 1 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 1 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 2 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 2 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 2 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.25.\n",
      "Finished run 2 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 2 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 2 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.1.\n",
      "Finished run 2 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 2 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 2 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 3 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.9.\n",
      "Finished run 3 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.75.\n",
      "Finished run 3 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 3 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 3 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 3 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 3 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 3 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 3 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 4 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.75.\n",
      "Finished run 4 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.75.\n",
      "Finished run 4 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 4 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 4 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 4 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 4 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 4 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 4 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 5 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.95.\n",
      "Finished run 5 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 5 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 5 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.5.\n",
      "Finished run 5 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 5 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 5 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 5 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 5 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 6 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.95.\n",
      "Finished run 6 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 6 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.5.\n",
      "Finished run 6 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 6 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 6 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.4.\n",
      "Finished run 6 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 6 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 6 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 7 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 7 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.001.\n",
      "Finished run 7 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.4.\n",
      "Finished run 7 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.001.\n",
      "Finished run 7 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 7 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 7 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 7 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 7 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 8 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.25.\n",
      "Finished run 8 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 8 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.9.\n",
      "Finished run 8 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.4.\n",
      "Finished run 8 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 8 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 8 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 8 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 8 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 9 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.4.\n",
      "Finished run 9 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.6.\n",
      "Finished run 9 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.001.\n",
      "Finished run 9 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.01.\n",
      "Finished run 9 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.01.\n",
      "Finished run 9 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 9 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.01.\n",
      "Finished run 9 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 9 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 10 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.001.\n",
      "Finished run 10 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.01.\n",
      "Finished run 10 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.01.\n",
      "Finished run 10 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.1.\n",
      "Finished run 10 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 10 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.01.\n",
      "Finished run 10 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 10 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 10 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 11 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.1.\n",
      "Finished run 11 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.5.\n",
      "Finished run 11 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 11 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 11 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 11 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.001.\n",
      "Finished run 11 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 11 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 11 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 12 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.5.\n",
      "Finished run 12 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.1.\n",
      "Finished run 12 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.25.\n",
      "Finished run 12 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.9.\n",
      "Finished run 12 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.001.\n",
      "Finished run 12 of TGR 1, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 2 is 0.25.\n",
      "Finished run 12 of TGR 2, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 3 is 0.001.\n",
      "Finished run 12 of TGR 3, scenario (250, 50, 0.5).\n",
      "-- Run 12 of 15 finished in scenario (250, 50, 0.5)!\n",
      "Finished run 13 of OLS, scenario (250, 50, 0.5).\n",
      "Best Lambda for LASSO is 0.01.\n",
      "Finished run 13 of LASSO, scenario (250, 50, 0.5).\n",
      "Best Lambda for Ridge is 0.25.\n",
      "Finished run 13 of Ridge, scenario (250, 50, 0.5).\n",
      "Best Lambda for Arctan is 0.1.\n",
      "Finished run 13 of Arctan, scenario (250, 50, 0.5).\n",
      "Best Lambda for Gaussian is 0.25.\n",
      "Finished run 13 of Gaussian, scenario (250, 50, 0.5).\n",
      "Best Lambda for TGR Setting 1 is 0.1.\n",
      "Finished run 13 of TGR 1, scenario (250, 50, 0.5).\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "def filter_scenarios(scenario):\n",
    "    n_sample, n_feature, n_nonzero_feature = scenario\n",
    "\n",
    "    if n_nonzero_feature == 0.1:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Step 1: Generate synthetic data using scenario\n",
    "n_epochs = 500\n",
    "runs = 15\n",
    "\n",
    "n_samples = [250]#[10, 100, 250]\n",
    "n_features = [50]#[10, 50, 25]\n",
    "n_nonzero =  [0.1, 0.5, 0.9]\n",
    "\n",
    "scenario_combinations = list(itertools.product(n_samples, n_features, n_nonzero))\n",
    "filtered_scenarios = [scen for scen in scenario_combinations if filter_scenarios(scen)]\n",
    "\n",
    "# Make Folder for Simulation Output\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "simulation_folder_path = f'Sample100_Simulation_{current_datetime}'\n",
    "os.makedirs(simulation_folder_path, exist_ok=True)\n",
    "\n",
    "for scen in filtered_scenarios:\n",
    "    run_simulation(scen, simulation_folder_path)\n",
    "    print(f'Finished Scenario {scen}!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muli-Threading Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multiprocessing...\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "def run_simulation_wrapper(scen, simulation_folder_path):\n",
    "    try:\n",
    "        print(f'Started Scenario {scen}!', flush=True)\n",
    "        run_simulation(scen, simulation_folder_path)  # Assuming run_simulation is defined\n",
    "        print(f'Finished Scenario {scen}!', flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scenario {scen}: {e}\", flush=True)\n",
    "        raise e  # Re-raise the error to ensure it stops the pool    \n",
    "    return scen\n",
    "\n",
    "# Step 1: Generate synthetic data using scenario\n",
    "#n_epochs = 500\n",
    "#runs = 1\n",
    "\n",
    "n_samples = [10, 100, 250, 500]\n",
    "n_features = [10] #[10, 50, 200]\n",
    "n_nonzero =  [0.1] #[0.1, 0.5, 0.9]\n",
    "\n",
    "scenario_combinations = list(itertools.product(n_samples, n_features, n_nonzero))\n",
    "\n",
    "# Make Folder for Simulation Output\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "simulation_folder_path = f'Final_Simulation_{current_datetime}'\n",
    "os.makedirs(simulation_folder_path, exist_ok=True)\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count()) # Create a pool of workers equal to the number of CPU cores\n",
    "\n",
    "print(\"Starting multiprocessing...\")\n",
    "results = [pool.apply_async(run_simulation_wrapper, args=(scen, simulation_folder_path)) for scen in scenario_combinations]\n",
    "\n",
    "pool.starmap(run_simulation_wrapper, [(scen, simulation_folder_path) for scen in scenario_combinations])\n",
    "print(\"Finishing multiprocessing...\")\n",
    "\n",
    "for r in results:\n",
    "    r.wait()  # Wait for the result\n",
    "\n",
    "# Check results and potential exceptions\n",
    "for r in results:\n",
    "    print(r.get())  \n",
    "    \n",
    "pool.close()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
