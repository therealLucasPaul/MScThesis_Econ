{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import log_hyperu as hyperu\n",
    "import tgr as tgr\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4798,  0.4873, -3.0128,  ...,  1.9991,  0.7848, -1.0195],\n",
      "        [-0.2106,  0.6268,  0.9318,  ..., -0.5429,  0.4307, -1.9257],\n",
      "        [ 1.2756, -1.1316,  0.8680,  ..., -0.8407, -0.3963, -0.2591],\n",
      "        ...,\n",
      "        [-1.3737,  0.0184,  1.1507,  ..., -0.8902,  0.5128, -0.5483],\n",
      "        [-0.4525,  1.2544,  1.0292,  ...,  0.3971, -0.7133, -0.6877],\n",
      "        [-0.3455, -0.0047, -0.2237,  ...,  0.0928,  0.3904,  1.0149]])\n"
     ]
    }
   ],
   "source": [
    "# Generating the data sets\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "# Structure of the data sets\n",
    "## Set X_A: Sparse Coefficients with many data points\n",
    "## Set X_B: Dense Coefficients with many data points\n",
    "## Set X_C: Sparse Coefficients with few data points\n",
    "## Set X_D: Dense Coefficients with few data points\n",
    "\n",
    "\n",
    "### Set X_A\n",
    "variables = 12\n",
    "sample = 100\n",
    "true_coefs = torch.tensor([[0],[0],[5.3],[4.2],[0],[0],[6.9],[0],[0],[0],[0],[0]])\n",
    "X = torch.randn(sample, variables)\n",
    "Y = X @ true_coefs + torch.randn(sample, 1) * 0.1\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 55.32939529418945\n",
      "Epoch [200/4000], Loss: 45.14422607421875\n",
      "Epoch [300/4000], Loss: 36.81026840209961\n",
      "Epoch [400/4000], Loss: 30.06134033203125\n",
      "Epoch [500/4000], Loss: 24.816471099853516\n",
      "Epoch [600/4000], Loss: 20.907426834106445\n",
      "Epoch [700/4000], Loss: 18.205690383911133\n",
      "Epoch [800/4000], Loss: 16.529497146606445\n",
      "Epoch [900/4000], Loss: 15.707762718200684\n",
      "Epoch [1000/4000], Loss: 15.401206016540527\n",
      "Epoch [1100/4000], Loss: 15.280069351196289\n",
      "Epoch [1200/4000], Loss: 15.237548828125\n",
      "Epoch [1300/4000], Loss: 15.218250274658203\n",
      "Epoch [1400/4000], Loss: 15.218034744262695\n",
      "Epoch [1500/4000], Loss: 15.204828262329102\n",
      "Epoch [1600/4000], Loss: 15.213384628295898\n",
      "Epoch [1700/4000], Loss: 15.21099853515625\n",
      "Epoch [1800/4000], Loss: 15.21127700805664\n",
      "Epoch [1900/4000], Loss: 15.211557388305664\n",
      "Epoch [2000/4000], Loss: 15.209331512451172\n",
      "Epoch [2100/4000], Loss: 15.209222793579102\n",
      "Epoch [2200/4000], Loss: 15.209370613098145\n",
      "Epoch [2300/4000], Loss: 15.206412315368652\n",
      "Epoch [2400/4000], Loss: 15.207270622253418\n",
      "Epoch [2500/4000], Loss: 15.209261894226074\n",
      "Epoch [2600/4000], Loss: 15.203600883483887\n",
      "Epoch [2700/4000], Loss: 15.211404800415039\n",
      "Epoch [2800/4000], Loss: 15.205522537231445\n",
      "Epoch [2900/4000], Loss: 15.207968711853027\n",
      "Epoch [3000/4000], Loss: 15.206814765930176\n",
      "Epoch [3100/4000], Loss: 15.208803176879883\n",
      "Epoch [3200/4000], Loss: 15.213080406188965\n",
      "Epoch [3300/4000], Loss: 15.207111358642578\n",
      "Epoch [3400/4000], Loss: 15.205595970153809\n",
      "Epoch [3500/4000], Loss: 15.201777458190918\n",
      "Epoch [3600/4000], Loss: 15.202284812927246\n",
      "Epoch [3700/4000], Loss: 15.209349632263184\n",
      "Epoch [3800/4000], Loss: 15.210536003112793\n",
      "Epoch [3900/4000], Loss: 15.206966400146484\n",
      "Epoch [4000/4000], Loss: 15.208505630493164\n",
      "With 4000 iterations, TG Regularization took 18.6507 seconds. On this system, that is roughly 0.004662680804729462 seconds per iteration.\n",
      "[0.0010959075298160315, -0.0021864117588847876, 4.732969284057617, 3.5899300575256348, -0.0005459622479975224, -0.0036597144789993763, 6.169013500213623, -0.001339899841696024, 0.0008271024562418461, 0.001468498958274722, -0.0023996394593268633, -0.0021053869277238846]\n"
     ]
    }
   ],
   "source": [
    "iterations = 4000\n",
    "starttime = time.time()\n",
    "trained_model2, coefs, loss_of_optimization = tgr.TripleGammaModel(X, Y, 1, 1, 30, 1, True, num_epochs=iterations) # Covariates, Targets, Penalty, a, c, kappa, normalization=True\n",
    "endtime = time.time()\n",
    "print(f'With {iterations} iterations, TG Regularization took {round(endtime-starttime,4)} seconds. On this system, that is roughly {(endtime-starttime)/iterations} seconds per iteration.')\n",
    "coefficients = trained_model2.linear.weight.detach().numpy()\n",
    "#intercept = trained_model2.linear.bias.item()\n",
    "\n",
    "# For LASSO Imitation: (X, Y, 1, 1, 30, 1, True, num_epochs=2000) # Covariates, Targets, Penalty, a, c, kappa, normalization=True\n",
    "\n",
    "#print(\"Coefficients General Function:\", coefficients)\n",
    "#print(\"Intercept General Function:\", intercept)\n",
    "print(coefficients[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 19.0086\n",
      "Epoch [200/4000], Loss: 15.6859\n",
      "Epoch [300/4000], Loss: 15.4875\n",
      "Epoch [400/4000], Loss: 15.4785\n",
      "Epoch [500/4000], Loss: 15.4944\n",
      "Epoch [600/4000], Loss: 15.4819\n",
      "Epoch [700/4000], Loss: 15.4776\n",
      "Epoch [800/4000], Loss: 15.4981\n",
      "Epoch [900/4000], Loss: 15.4745\n",
      "Epoch [1000/4000], Loss: 15.4835\n",
      "Epoch [1100/4000], Loss: 15.4936\n",
      "Epoch [1200/4000], Loss: 15.4895\n",
      "Epoch [1300/4000], Loss: 15.4747\n",
      "Epoch [1400/4000], Loss: 15.4798\n",
      "Epoch [1500/4000], Loss: 15.4760\n",
      "Epoch [1600/4000], Loss: 15.4725\n",
      "Epoch [1700/4000], Loss: 15.4822\n",
      "Epoch [1800/4000], Loss: 15.4826\n",
      "Epoch [1900/4000], Loss: 15.4856\n",
      "Epoch [2000/4000], Loss: 15.4977\n",
      "Epoch [2100/4000], Loss: 15.4850\n",
      "Epoch [2200/4000], Loss: 15.4764\n",
      "Epoch [2300/4000], Loss: 15.4907\n",
      "Epoch [2400/4000], Loss: 15.4766\n",
      "Epoch [2500/4000], Loss: 15.4710\n",
      "Epoch [2600/4000], Loss: 15.4752\n",
      "Epoch [2700/4000], Loss: 15.4836\n",
      "Epoch [2800/4000], Loss: 15.4781\n",
      "Epoch [2900/4000], Loss: 15.4752\n",
      "Epoch [3000/4000], Loss: 15.4802\n",
      "Epoch [3100/4000], Loss: 15.4754\n",
      "Epoch [3200/4000], Loss: 15.4912\n",
      "Epoch [3300/4000], Loss: 15.4768\n",
      "Epoch [3400/4000], Loss: 15.4871\n",
      "Epoch [3500/4000], Loss: 15.4874\n",
      "Epoch [3600/4000], Loss: 15.4924\n",
      "Epoch [3700/4000], Loss: 15.4857\n",
      "Epoch [3800/4000], Loss: 15.4753\n",
      "Epoch [3900/4000], Loss: 15.4921\n",
      "Epoch [4000/4000], Loss: 15.4736\n",
      "With 4000 iterations, Regular LASSO Regularization took 6.6823 seconds. On this system, that is roughly 0.001670568823814392 seconds per iteration.\n",
      "linear.weight: [[0.0074189528822898865, -0.00737436767667532, 4.71066427230835, 3.571519374847412, -0.010000970214605331, -0.007275632582604885, 6.135548114776611, 0.005040994379669428, -0.0063200825825333595, -0.005138209089636803, 8.25393944978714e-05, -0.006965739652514458]]\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "# Define your model\n",
    "starttime = time.time()\n",
    "class LinearRegressionLasso(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionLasso, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 12\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 4000\n",
    "lambda_lasso = 1  # L1 regularization parameter\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegressionLasso(input_size, output_size)\n",
    "\n",
    "# Define loss function (MSE loss with L1 regularization)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    # L1 regularization term\n",
    "    l1_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.norm(param, p=1)\n",
    "    \n",
    "    # Total loss with L1 regularization\n",
    "    loss += lambda_lasso * l1_reg\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "endtime = time.time()\n",
    "print(f'With {num_epochs} iterations, Regular LASSO Regularization took {round(endtime-starttime,4)} seconds. On this system, that is roughly {(endtime-starttime)/num_epochs} seconds per iteration.')\n",
    "\n",
    "# After training, you can access the learned coefficients\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f'{name}: {param.data.tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 4.2589\n",
      "Epoch [200/4000], Loss: 0.4515\n",
      "Epoch [300/4000], Loss: 0.0659\n",
      "Epoch [400/4000], Loss: 0.0175\n",
      "Epoch [500/4000], Loss: 0.0108\n",
      "Epoch [600/4000], Loss: 0.0098\n",
      "Epoch [700/4000], Loss: 0.0096\n",
      "Epoch [800/4000], Loss: 0.0096\n",
      "Epoch [900/4000], Loss: 0.0096\n",
      "Epoch [1000/4000], Loss: 0.0096\n",
      "Epoch [1100/4000], Loss: 0.0096\n",
      "Epoch [1200/4000], Loss: 0.0096\n",
      "Epoch [1300/4000], Loss: 0.0096\n",
      "Epoch [1400/4000], Loss: 0.0096\n",
      "Epoch [1500/4000], Loss: 0.0096\n",
      "Epoch [1600/4000], Loss: 0.0096\n",
      "Epoch [1700/4000], Loss: 0.0096\n",
      "Epoch [1800/4000], Loss: 0.0096\n",
      "Epoch [1900/4000], Loss: 0.0096\n",
      "Epoch [2000/4000], Loss: 0.0096\n",
      "Epoch [2100/4000], Loss: 0.0096\n",
      "Epoch [2200/4000], Loss: 0.0096\n",
      "Epoch [2300/4000], Loss: 0.0096\n",
      "Epoch [2400/4000], Loss: 0.0096\n",
      "Epoch [2500/4000], Loss: 0.0096\n",
      "Epoch [2600/4000], Loss: 0.0096\n",
      "Epoch [2700/4000], Loss: 0.0096\n",
      "Epoch [2800/4000], Loss: 0.0096\n",
      "Epoch [2900/4000], Loss: 0.0096\n",
      "Epoch [3000/4000], Loss: 0.0096\n",
      "Epoch [3100/4000], Loss: 0.0096\n",
      "Epoch [3200/4000], Loss: 0.0096\n",
      "Epoch [3300/4000], Loss: 0.0096\n",
      "Epoch [3400/4000], Loss: 0.0096\n",
      "Epoch [3500/4000], Loss: 0.0096\n",
      "Epoch [3600/4000], Loss: 0.0096\n",
      "Epoch [3700/4000], Loss: 0.0096\n",
      "Epoch [3800/4000], Loss: 0.0096\n",
      "Epoch [3900/4000], Loss: 0.0096\n",
      "Epoch [4000/4000], Loss: 0.0096\n",
      "With 4000 iterations, Regular OLS took 4.8665 seconds. On this system, that is roughly 0.0012166162729263306 seconds per iteration.\n",
      "linear.weight: [[0.0016218326054513454, 0.010086349211633205, 5.302742958068848, 4.206653594970703, 0.004735542926937342, 0.007845431566238403, 6.915150165557861, 0.004620492458343506, -0.0020585942547768354, -0.004125183913856745, 0.0052244472317397594, 0.002070249058306217]]\n"
     ]
    }
   ],
   "source": [
    "# Normale Regression\n",
    "\n",
    "starttime = time.time()\n",
    "class LinearRegressionLasso(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionLasso, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 12\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 4000\n",
    "lambda_lasso = 0 # To get OLS Estimate\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegressionLasso(input_size, output_size)\n",
    "\n",
    "# Define loss function (MSE loss with L1 regularization)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    # L1 regularization term\n",
    "    l1_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.norm(param, p=1)\n",
    "    \n",
    "    # Total loss with L1 regularization\n",
    "    loss += lambda_lasso * l1_reg\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "endtime = time.time()\n",
    "print(f'With {num_epochs} iterations, Regular OLS took {round(endtime-starttime,4)} seconds. On this system, that is roughly {(endtime-starttime)/num_epochs} seconds per iteration.')\n",
    "\n",
    "# After training, you can access the learned coefficients\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f'{name}: {param.data.tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
