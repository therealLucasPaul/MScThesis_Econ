{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import log_hyperu as hyperu\n",
    "import tgr as tgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4798,  0.4873, -3.0128,  ...,  1.9991,  0.7848, -1.0195],\n",
      "        [-0.2106,  0.6268,  0.9318,  ..., -0.5429,  0.4307, -1.9257],\n",
      "        [ 1.2756, -1.1316,  0.8680,  ..., -0.8407, -0.3963, -0.2591],\n",
      "        ...,\n",
      "        [-1.3737,  0.0184,  1.1507,  ..., -0.8902,  0.5128, -0.5483],\n",
      "        [-0.4525,  1.2544,  1.0292,  ...,  0.3971, -0.7133, -0.6877],\n",
      "        [-0.3455, -0.0047, -0.2237,  ...,  0.0928,  0.3904,  1.0149]])\n"
     ]
    }
   ],
   "source": [
    "# Generating the data sets\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "# Structure of the data sets\n",
    "## Set X_A: Sparse Coefficients with many data points\n",
    "## Set X_B: Dense Coefficients with many data points\n",
    "## Set X_C: Sparse Coefficients with few data points\n",
    "## Set X_D: Dense Coefficients with few data points\n",
    "\n",
    "\n",
    "### Set X_A\n",
    "variables = 12\n",
    "sample = 100\n",
    "true_coefs = torch.tensor([[0],[0],[5.3],[4.2],[0],[0],[6.9],[0],[0],[0],[0],[0]])\n",
    "X = torch.randn(sample, variables)\n",
    "Y = X @ true_coefs + torch.randn(sample, 1) * 0.1\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 54.46653747558594\n",
      "Epoch [200/2000], Loss: 42.6019401550293\n",
      "Epoch [300/2000], Loss: 32.48612976074219\n",
      "Epoch [400/2000], Loss: 24.077037811279297\n",
      "Epoch [500/2000], Loss: 17.27841567993164\n",
      "Epoch [600/2000], Loss: 11.930946350097656\n",
      "Epoch [700/2000], Loss: 7.806328296661377\n",
      "Epoch [800/2000], Loss: 4.86722469329834\n",
      "Epoch [900/2000], Loss: 2.9005184173583984\n",
      "Epoch [1000/2000], Loss: 1.7011820077896118\n",
      "Epoch [1100/2000], Loss: 1.1852614879608154\n",
      "Epoch [1200/2000], Loss: 0.9131882786750793\n",
      "Epoch [1300/2000], Loss: 0.797982931137085\n",
      "Epoch [1400/2000], Loss: 0.7394814491271973\n",
      "Epoch [1500/2000], Loss: 0.7299396991729736\n",
      "Epoch [1600/2000], Loss: 0.7193539142608643\n",
      "Epoch [1700/2000], Loss: 0.7230297327041626\n",
      "Epoch [1800/2000], Loss: 0.7113962173461914\n",
      "Epoch [1900/2000], Loss: 0.7014321088790894\n",
      "Epoch [2000/2000], Loss: 0.7086474895477295\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucas Paul\\Documents\\GitHub_Repos\\MScThesis_Econ\\02_simulation\\simulation_tgr.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m coefficients \u001b[39m=\u001b[39m trained_model2\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#intercept = trained_model2.linear.bias.item()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#print(\"Coefficients General Function:\", coefficients)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#print(\"Intercept General Function:\", intercept)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/02_simulation/simulation_tgr.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcoefficients\u001b[39m:\u001b[39;00m\u001b[39m.20f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "trained_model2, coefs, loss_of_optimization = tgr.TripleGammaModel(X, Y, 0.05, 0.75, 0.1, 2, True, num_epochs=2000) # Covariates, Targets, Penalty, a, c, kappa, normalization=True\n",
    "coefficients = trained_model2.linear.weight.detach().numpy()\n",
    "#intercept = trained_model2.linear.bias.item()\n",
    "\n",
    "#print(\"Coefficients General Function:\", coefficients)\n",
    "#print(\"Intercept General Function:\", intercept)\n",
    "print(coefficients[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 19.0645\n",
      "Epoch [200/1000], Loss: 15.7905\n",
      "Epoch [300/1000], Loss: 15.5970\n",
      "Epoch [400/1000], Loss: 15.5760\n",
      "Epoch [500/1000], Loss: 15.6062\n",
      "Epoch [600/1000], Loss: 15.5800\n",
      "Epoch [700/1000], Loss: 15.5879\n",
      "Epoch [800/1000], Loss: 15.5872\n",
      "Epoch [900/1000], Loss: 15.5942\n",
      "Epoch [1000/1000], Loss: 15.5884\n",
      "linear.weight: tensor([[-6.9520e-03, -7.7376e-03,  4.6682e+00,  3.6015e+00,  7.5944e-03,\n",
      "         -3.3017e-03,  6.1469e+00, -7.0554e-03,  3.5510e-03, -3.7710e-03,\n",
      "          1.5011e-03,  2.4193e-03]])\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "# Define your model\n",
    "class LinearRegressionLasso(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionLasso, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 12\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "lambda_lasso = 1  # L1 regularization parameter\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegressionLasso(input_size, output_size)\n",
    "\n",
    "# Define loss function (MSE loss with L1 regularization)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    # L1 regularization term\n",
    "    l1_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.norm(param, p=1)\n",
    "    \n",
    "    # Total loss with L1 regularization\n",
    "    loss += lambda_lasso * l1_reg\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can access the learned coefficients\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f'{name}: {param.data}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
