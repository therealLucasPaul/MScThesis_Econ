{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import log_hyperu as hyperu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4938],\n",
      "        [0.1951],\n",
      "        [5.2891],\n",
      "        [4.2099]])\n"
     ]
    }
   ],
   "source": [
    "# Simulate Data\n",
    "torch.manual_seed(1234)  # For reproducibility\n",
    "\n",
    "## Data Set 1 - Basic Coefficients - Normal Sample Size\n",
    "variables = 4\n",
    "sample = 100\n",
    "true_coefs = torch.tensor([[0.5],[0.2],[5.3],[4.2]])\n",
    "X = torch.randn(sample, variables)\n",
    "Y = X @ true_coefs + torch.randn(sample, 1) * 0.1 \n",
    "\n",
    "# Basic OLS Estimate\n",
    "beta_OLS = torch.linalg.lstsq(X, Y).solution\n",
    "print(beta_OLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 30.822105407714844\n",
      "Epoch [200/1000], Loss: 30.587779998779297\n",
      "Epoch [300/1000], Loss: 30.495723724365234\n",
      "Epoch [400/1000], Loss: 30.590938568115234\n",
      "Epoch [500/1000], Loss: 30.5347900390625\n",
      "Epoch [600/1000], Loss: 30.57209014892578\n",
      "Epoch [700/1000], Loss: 30.573200225830078\n",
      "Epoch [800/1000], Loss: 30.569324493408203\n",
      "Epoch [900/1000], Loss: 30.54937744140625\n",
      "Epoch [1000/1000], Loss: 30.59555435180664\n",
      "Coefficients: [[-0.01088759 -0.01968116  3.194002    2.367281  ]]\n",
      "Intercept: 0.007841205224394798\n"
     ]
    }
   ],
   "source": [
    "## LASSO Implementation\n",
    "class LassoRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LassoRegression, self).__init__()\n",
    "        self.linear = nn.Linear(variables, 1) \n",
    "        self.l1_penalty = nn.L1Loss(reduction='sum')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def lasso_regression(X, y, lambda_l1, num_epochs=1000, lr=0.01):\n",
    "    # Initialize the model\n",
    "    model = LassoRegression(X.shape[1])\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        \n",
    "        # Compute L1 regularization term\n",
    "        l1_reg = torch.tensor(0., requires_grad=True)\n",
    "        for param in model.parameters():\n",
    "            l1_reg = l1_reg + torch.norm(param, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = nn.MSELoss()(outputs, y) + lambda_l1 * l1_reg\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    # Return the trained model\n",
    "    return model\n",
    "\n",
    "trained_model = lasso_regression(X, Y, 4)\n",
    "coefficients = trained_model.linear.weight.detach().numpy()\n",
    "intercept = trained_model.linear.bias.item()\n",
    "\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 31.113710403442383\n",
      "Epoch [200/1000], Loss: 22.55941390991211\n",
      "Epoch [300/1000], Loss: 14.998287200927734\n",
      "Epoch [400/1000], Loss: 9.139435768127441\n",
      "Epoch [500/1000], Loss: 5.041503429412842\n",
      "Epoch [600/1000], Loss: 2.444061279296875\n",
      "Epoch [700/1000], Loss: -0.793156623840332\n",
      "Epoch [800/1000], Loss: 1.2230231761932373\n",
      "Epoch [900/1000], Loss: 1.4403553009033203\n",
      "Epoch [1000/1000], Loss: 1.4940588474273682\n",
      "Coefficients General Function: [[0.49410915 0.1903951  5.2835255  4.2086163 ]]\n",
      "Intercept General Function: -0.007902863435447216\n"
     ]
    }
   ],
   "source": [
    "# Triple-Gamma-Regularization\n",
    "\n",
    "class CustomRegularizationModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomRegularizationModel, self).__init__()\n",
    "        self.linear = nn.Linear(variables, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def custom_regularization_loss(outputs, targets, coefficients, penalty, a, c, kappa):\n",
    "    phi = (2*c)/((kappa**2)*a)\n",
    "    # Squared loss\n",
    "    squared_loss = nn.MSELoss()(outputs, targets)\n",
    "    \n",
    "    # Penalty term\n",
    "    penalty_term = penalty * torch.norm(coefficients, p=1)\n",
    "    \n",
    "    penalty_loss = 0\n",
    "    for coefs in coefficients[0]:\n",
    "        beta = torch.tensor([[coefs.item()]])\n",
    "        loss_individual = hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),(beta**2)/(2*phi))\n",
    "        penalty_loss = penalty_loss + loss_individual\n",
    "    \n",
    "    # Combined loss\n",
    "    loss = squared_loss - penalty_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_with_regularization(X, y, penalty, a, c, kappa, num_epochs=1000, lr=0.01):\n",
    "    model = CustomRegularizationModel(X.shape[1])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = custom_regularization_loss(outputs, y, model.linear.weight, penalty, a, c, kappa)\n",
    "        loss.backward()\n",
    "        \n",
    "        #Gradient Clipping???\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "trained_model2 = train_model_with_regularization(X, Y, 4, 0.1, 0.1, 2) # Covariates, Targets, Penalty, a, c, kappa\n",
    "coefficients = trained_model2.linear.weight.detach().numpy()\n",
    "intercept = trained_model2.linear.bias.item()\n",
    "\n",
    "print(\"Coefficients General Function:\", coefficients)\n",
    "print(\"Intercept General Function:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02184849  0.01860901  3.1137912   2.3287895 ]]\n",
      "tensor([[0.5479]])\n",
      "tensor([[0.5515]])\n",
      "tensor([[-1.1820]])\n",
      "tensor([[-0.9224]])\n",
      "tensor([[-1.0050]])\n"
     ]
    }
   ],
   "source": [
    "Custom Loss Test\n",
    "print(coefficients)\n",
    "a = torch.tensor([[0.5]])\n",
    "b = torch.tensor([[0.5]])\n",
    "c = torch.tensor([[0.5]])\n",
    "custom_loss = 0\n",
    "\n",
    "for coefs in coefficients[0]:\n",
    "    beta = torch.tensor([[coefs]])\n",
    "    loss_individual = hyperu.log_hyperu(a,b,beta**2)\n",
    "    print(loss_individual)\n",
    "    custom_loss = custom_loss + loss_individual\n",
    "\n",
    "print(custom_loss)\n",
    "#print(hyperu.log_hyperu(a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6707]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.1\n",
    "c = 0.1\n",
    "kappa = 2\n",
    "phi = (2*c)/((kappa**2)*a)\n",
    "coef = torch.tensor([[4]])\n",
    "\n",
    "hyperu.log_hyperu(torch.tensor([[c+0.5]]),torch.tensor([[1.5-a]]),(coef**2)/(2*phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
