{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import torch\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           area  stories  furnishingstatus_semi-furnished  \\\n",
      "0    689.340557        3                            False   \n",
      "1    832.411238        4                            False   \n",
      "2    925.314278        2                             True   \n",
      "3    696.772800        2                            False   \n",
      "4    689.340557        2                            False   \n",
      "..          ...      ...                              ...   \n",
      "540  278.709120        1                            False   \n",
      "541  222.967296        1                             True   \n",
      "542  336.309005        1                            False   \n",
      "543  270.347846        1                            False   \n",
      "544  357.676704        2                            False   \n",
      "\n",
      "     furnishingstatus_unfurnished  \n",
      "0                           False  \n",
      "1                           False  \n",
      "2                           False  \n",
      "3                           False  \n",
      "4                           False  \n",
      "..                            ...  \n",
      "540                          True  \n",
      "541                         False  \n",
      "542                          True  \n",
      "543                         False  \n",
      "544                          True  \n",
      "\n",
      "[545 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"sample_data/housing.csv\")\n",
    "\n",
    "Y = data.price.values/1000000\n",
    "data = data[['area',\"stories\",\"furnishingstatus\"]] #data.iloc[:, 1:]\n",
    "X_categorical = pd.get_dummies(data[[\"furnishingstatus\"]], prefix=\"furnishingstatus\")\n",
    "X_numeric = data.drop(columns=[\"furnishingstatus\"])\n",
    "X = pd.concat([X_numeric, X_categorical], axis=1)\n",
    "X[\"area\"] = X[\"area\"]*0.09290304\n",
    "X = X.drop(columns=[\"furnishingstatus_furnished\"])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "area: 0.0044\n",
      "stories: 0.7806\n",
      "furnishingstatus_semi-furnished: -0.2648\n",
      "furnishingstatus_unfurnished: -0.8934\n",
      "Intercept: 1.6547\n",
      "R^2: 0.4649\n",
      "Mean Squared Error: 1.8686\n"
     ]
    }
   ],
   "source": [
    "# Simple Linear Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y)\n",
    "\n",
    "def regression_summary(model, X, y, feature_names):\n",
    "    # Print coefficients\n",
    "    print(\"Coefficients:\")\n",
    "    for feature_name, coef in zip(feature_names, model.coef_):\n",
    "        print(f\"{feature_name}: {coef:.4f}\")\n",
    "\n",
    "    # Print intercept\n",
    "    print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "\n",
    "    # Print R^2 value\n",
    "    r_squared = model.score(X, y)\n",
    "    print(f\"R^2: {r_squared:.4f}\")\n",
    "\n",
    "    # Print mean squared error\n",
    "    predictions = model.predict(X)\n",
    "    mse = np.mean((predictions - y) ** 2)\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    \n",
    "\n",
    "regression_summary(model, X, Y, feature_names=X)  # Assuming the last column is the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucas Paul\\Documents\\GitHub_Repos\\MScThesis_Econ\\06_general_code\\PythonRegression_Testing.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/06_general_code/PythonRegression_Testing.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create and fit the Lasso model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/06_general_code/PythonRegression_Testing.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lasso_model \u001b[39m=\u001b[39m Lasso(alpha\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)  \u001b[39m# You can specify the regularization strength using the alpha parameter\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/06_general_code/PythonRegression_Testing.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lasso_model\u001b[39m.\u001b[39mfit(X, Y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas%20Paul/Documents/GitHub_Repos/MScThesis_Econ/06_general_code/PythonRegression_Testing.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Print coefficients\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# Create and fit the Lasso model\n",
    "lasso_model = Lasso(alpha=0.5)  # You can specify the regularization strength using the alpha parameter\n",
    "lasso_model.fit(X, Y)\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Coefficients:\", lasso_model.coef_)\n",
    "\n",
    "# Print intercept\n",
    "print(\"Intercept:\", lasso_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [100/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [200/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [300/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [400/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [500/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [600/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [700/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [800/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [900/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Iteration [1000/1000], Loss: 1.6492743492126465, x: 1.1395385265350342, y: 0.9999998807907104\n",
      "Final values: x = 1.1395385265350342, y = 0.9999998807907104, function value = 1.2673931121826172\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Define the function you want to optimize\n",
    "def arbitrary_function(x, y):\n",
    "    return 3*(x**4) - 6*(x**2) + 4 + (y-1)**2\n",
    "\n",
    "# Step 2: Create PyTorch tensors for the variables\n",
    "x = torch.tensor(0.1, requires_grad=True)\n",
    "y = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "# Step 3: Define learning rate and number of iterations\n",
    "learning_rate = 0.1\n",
    "num_iterations = 1000\n",
    "\n",
    "# Step 4: Define the optimizer\n",
    "optimizer = torch.optim.SGD([x, y], lr=learning_rate)\n",
    "\n",
    "# Step 5 & 6: Gradient descent loop\n",
    "for i in range(num_iterations):\n",
    "    # Compute the function value\n",
    "    loss = arbitrary_function(x, y)\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update variables using gradients and optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f'Iteration [{i+1}/{num_iterations}], Loss: {loss.item()}, x: {x.item()}, y: {y.item()}')\n",
    "\n",
    "# After optimization, print the final values of x, y, and the function value\n",
    "print(f'Final values: x = {x.item()}, y = {y.item()}, function value = {arbitrary_function(x, y).item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4117],\n",
      "        [-0.8997],\n",
      "        [ 0.4821]])\n",
      "Iteration [100/2000], Loss: 0.4896484315395355, Coefs: [[-0.05855541676282883], [-0.5919321775436401], [-0.13198015093803406]]\n",
      "Iteration [200/2000], Loss: 0.028152892366051674, Coefs: [[-0.35103732347488403], [-0.835435152053833], [0.3442519009113312]]\n",
      "Iteration [300/2000], Loss: 0.008403917774558067, Coefs: [[-0.3903820514678955], [-0.8924943804740906], [0.4510281980037689]]\n",
      "Iteration [400/2000], Loss: 0.007478117942810059, Coefs: [[-0.39664703607559204], [-0.9058646559715271], [0.4743713438510895]]\n",
      "Iteration [500/2000], Loss: 0.007433771621435881, Coefs: [[-0.3977838456630707], [-0.9089432954788208], [0.4794524013996124]]\n",
      "Iteration [600/2000], Loss: 0.0074316333048045635, Coefs: [[-0.3980080485343933], [-0.9096410274505615], [0.4805600345134735]]\n",
      "Iteration [700/2000], Loss: 0.007431529927998781, Coefs: [[-0.39805448055267334], [-0.9097973704338074], [0.480802059173584]]\n",
      "Iteration [800/2000], Loss: 0.007431524805724621, Coefs: [[-0.3980642855167389], [-0.9098320603370667], [0.4808550179004669]]\n",
      "Iteration [900/2000], Loss: 0.0074315243400633335, Coefs: [[-0.3980661928653717], [-0.909839928150177], [0.48086661100387573]]\n",
      "Iteration [1000/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1100/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1200/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1300/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1400/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1500/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1600/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1700/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1800/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [1900/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "Iteration [2000/2000], Loss: 0.0074315257370471954, Coefs: [[-0.39806637167930603], [-0.9098402261734009], [0.48086872696876526]]\n",
      "True coefficients:\n",
      "tensor([[-0.4117],\n",
      "        [-0.8997],\n",
      "        [ 0.4821]])\n",
      "Estimated coefficients:\n",
      "tensor([[-0.3981],\n",
      "        [-0.9098],\n",
      "        [ 0.4809]], requires_grad=True)\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Generate random data for testing\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Number of samples and features\n",
    "num_samples = 100\n",
    "num_features = 3\n",
    "\n",
    "# Generate random data for design matrix X and response vector Y\n",
    "X = torch.randn(num_samples, num_features)\n",
    "true_coefficients = torch.randn(num_features, 1)  # True coefficients for each feature\n",
    "print(true_coefficients)\n",
    "Y = X @ true_coefficients + torch.randn(num_samples, 1) * 0.1  # Adding some noise to Y\n",
    "\n",
    "# Step 2: Define the squared residuals loss function\n",
    "def squared_residuals_loss(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Compute the squared residuals loss (mean squared error).\n",
    "\n",
    "    Args:\n",
    "    - y_pred: Predicted values (tensor).\n",
    "    - y_true: True values (tensor).\n",
    "\n",
    "    Returns:\n",
    "    - Loss value (scalar tensor).\n",
    "    \"\"\"\n",
    "    return torch.mean((y_pred - y_true)**2)\n",
    "\n",
    "# Step 3: Define the model parameters (coefficients) to be optimized\n",
    "coefficients = torch.randn(num_features, 1, requires_grad=True)\n",
    "\n",
    "# Step 4: Define the learning rate and number of iterations for gradient descent\n",
    "learning_rate = 0.01\n",
    "num_iterations = 2000\n",
    "\n",
    "# Step 5: Gradient descent loop\n",
    "for i in range(num_iterations):\n",
    "    # Compute predicted values\n",
    "    y_pred = X @ coefficients\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = squared_residuals_loss(y_pred, Y)\n",
    "    \n",
    "    # Zero the gradients\n",
    "    if coefficients.grad is not None:\n",
    "        coefficients.grad.zero_()\n",
    "    \n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters using gradients and learning rate\n",
    "    coefficients.data -= learning_rate * coefficients.grad\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f'Iteration [{i+1}/{num_iterations}], Loss: {loss.item()}, Coefs: {coefficients.data.tolist()}')\n",
    "\n",
    "# After optimization, print the estimated coefficients\n",
    "print('True coefficients:')\n",
    "print(true_coefficients)\n",
    "print('Estimated coefficients:')\n",
    "print(coefficients)\n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
